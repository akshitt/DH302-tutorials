{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "087af8f6"
   },
   "source": [
    "# Targeted Selection Demo For Biomedical Datasets With Rare Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a0fc69c"
   },
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tOFuAsDz1a7b"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/decile-team/trust.git\n",
    "# !pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ submodlib\n",
    "# !git clone https://github.com/decile-team/distil.git\n",
    "# !pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3b905244"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import copy\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from matplotlib import pyplot as plt\n",
    "from trust.trust.utils.models.resnet import ResNet18\n",
    "from trust.trust.utils.models.resnet import ResNet50\n",
    "from trust.trust.utils.custom_dataset_medmnist import load_biodataset_custom\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "from math import floor\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from trust.trust.strategies.smi import SMI\n",
    "from trust.trust.strategies.random_sampling import RandomSampling\n",
    "from distil.distil.active_learning_strategies.entropy_sampling import EntropySampling\n",
    "from distil.distil.active_learning_strategies.badge import BADGE\n",
    "\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "from trust.trust.utils.utils import *\n",
    "from trust.trust.utils.viz import tsne_smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec462346"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5c36c6b4"
   },
   "outputs": [],
   "source": [
    "def model_eval_loss(data_loader, model, criterion):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "                \n",
    "def create_model(name, num_cls, device, embedding_type):\n",
    "    if name == 'ResNet18':\n",
    "        if embedding_type == \"gradients\":\n",
    "            model = ResNet18(num_cls)\n",
    "        else:\n",
    "            model = models.resnet18()\n",
    "    elif name == 'ResNet50':\n",
    "        if embedding_type == \"gradients\":\n",
    "            model = ResNet50(num_cls)\n",
    "        else:\n",
    "            model = models.resnet50()\n",
    "    elif name == 'MnistNet':\n",
    "        model = MnistNet()\n",
    "    elif name == 'ResNet164':\n",
    "        model = ResNet164(num_cls)\n",
    "    model.apply(init_weights)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def loss_function():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion_nored = nn.CrossEntropyLoss(reduction='none')\n",
    "    return criterion, criterion_nored\n",
    "\n",
    "def optimizer_with_scheduler(model, num_epochs, learning_rate, m=0.9, wd=5e-4):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                          momentum=m, weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def optimizer_without_scheduler(model, learning_rate, m=0.9, wd=5e-4):\n",
    "#     optimizer = optim.Adam(model.parameters(),weight_decay=wd)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                          momentum=m, weight_decay=wd)\n",
    "    return optimizer\n",
    "\n",
    "def generate_cumulative_timing(mod_timing):\n",
    "    tmp = 0\n",
    "    mod_cum_timing = np.zeros(len(mod_timing))\n",
    "    for i in range(len(mod_timing)):\n",
    "        tmp += mod_timing[i]\n",
    "        mod_cum_timing[i] = tmp\n",
    "    return mod_cum_timing/3600\n",
    "\n",
    "def displayTable(val_err_log, tst_err_log):\n",
    "    col1 = [str(i) for i in range(10)]\n",
    "    val_acc = [str(100-i) for i in val_err_log]\n",
    "    tst_acc = [str(100-i) for i in tst_err_log]\n",
    "    table = [col1, val_acc, tst_acc]\n",
    "    table = map(list, zip(*table))\n",
    "    print(tabulate(table, headers=['Class', 'Val Accuracy', 'Test Accuracy'], tablefmt='orgtbl'))\n",
    "    print('Test accuracy is as follows - ')\n",
    "    for i in tst_acc:\n",
    "        print(i)\n",
    "        \n",
    "\n",
    "def find_err_per_class(test_set, val_set, final_val_classifications, final_val_predictions, final_tst_classifications, \n",
    "                       final_tst_predictions, saveDir, prefix):\n",
    "    val_err_idx = list(np.where(np.array(final_val_classifications) == False)[0])\n",
    "    tst_err_idx = list(np.where(np.array(final_tst_classifications) == False)[0])\n",
    "    val_class_err_idxs = []\n",
    "    tst_err_log = []\n",
    "    val_err_log = []\n",
    "    for i in range(num_cls):\n",
    "        tst_class_idxs = list(torch.where(torch.Tensor(test_set.targets) == i)[0].cpu().numpy())\n",
    "        val_class_idxs = list(torch.where(torch.Tensor(val_set.targets.float()) == i)[0].cpu().numpy())\n",
    "        #err classifications per class\n",
    "        val_err_class_idx = set(val_err_idx).intersection(set(val_class_idxs))\n",
    "        tst_err_class_idx = set(tst_err_idx).intersection(set(tst_class_idxs))\n",
    "        if(len(val_class_idxs)>0):\n",
    "            val_error_perc = round((len(val_err_class_idx)/len(val_class_idxs))*100,2)\n",
    "        else:\n",
    "            val_error_perc = 0\n",
    "        tst_error_perc = round((len(tst_err_class_idx)/len(tst_class_idxs))*100,2)\n",
    "#         print(\"val, test error% for class \", i, \" : \", val_error_perc, tst_error_perc)\n",
    "        val_class_err_idxs.append(val_err_class_idx)\n",
    "        tst_err_log.append(tst_error_perc)\n",
    "        val_err_log.append(val_error_perc)\n",
    "    displayTable(val_err_log, tst_err_log)\n",
    "    tst_err_log.append(sum(tst_err_log)/len(tst_err_log))\n",
    "    val_err_log.append(sum(val_err_log)/len(val_err_log))\n",
    "    return tst_err_log, val_err_log, val_class_err_idxs\n",
    "\n",
    "\n",
    "def aug_train_subset(train_set, lake_set, true_lake_set, subset, lake_subset_idxs, budget, augrandom=False):\n",
    "    all_lake_idx = list(range(len(lake_set)))\n",
    "    if(not(len(subset)==budget) and augrandom):\n",
    "        print(\"Budget not filled, adding \", str(int(budget) - len(subset)), \" randomly.\")\n",
    "        remain_budget = int(budget) - len(subset)\n",
    "        remain_lake_idx = list(set(all_lake_idx) - set(subset))\n",
    "        random_subset_idx = list(np.random.choice(np.array(remain_lake_idx), size=int(remain_budget), replace=False))\n",
    "        subset += random_subset_idx\n",
    "    if str(type(true_lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        lake_ss = SubsetWithTargets(true_lake_set, subset, torch.Tensor(true_lake_set.targets.astype(np.float))[subset])\n",
    "    else:\n",
    "        lake_ss = SubsetWithTargets(true_lake_set, subset, torch.Tensor(true_lake_set.targets.float())[subset])\n",
    "    remain_lake_idx = list(set(all_lake_idx) - set(lake_subset_idxs))\n",
    "    if str(type(true_lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        remain_lake_set = SubsetWithTargets(lake_set, remain_lake_idx, torch.Tensor(lake_set.targets.astype(np.float))[remain_lake_idx])\n",
    "    else:\n",
    "        remain_lake_set = SubsetWithTargets(lake_set, remain_lake_idx, torch.Tensor(lake_set.targets.float())[remain_lake_idx])\n",
    "    if str(type(true_lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        remain_true_lake_set = SubsetWithTargets(true_lake_set, remain_lake_idx, torch.Tensor(true_lake_set.targets.astype(np.float))[remain_lake_idx])\n",
    "    else:\n",
    "        remain_true_lake_set = SubsetWithTargets(true_lake_set, remain_lake_idx, torch.Tensor(true_lake_set.targets.float())[remain_lake_idx])\n",
    "#     print(len(lake_ss),len(remain_lake_set),len(lake_set))\n",
    "    aug_train_set = torch.utils.data.ConcatDataset([train_set, lake_ss])\n",
    "    aug_trainloader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True, pin_memory=True)\n",
    "    return aug_train_set, remain_lake_set, remain_true_lake_set, lake_ss\n",
    "                        \n",
    "def getQuerySet(val_set, val_class_err_idxs, imb_cls_idx, miscls):\n",
    "    miscls_idx = []\n",
    "    if miscls == 'target':\n",
    "        # List of number denoting misclassified examples per class\n",
    "        print(\"\\n val_class_err_idxs - \", val_class_err_idxs)\n",
    "        len_val_class_error_idx = []\n",
    "        for i in val_class_err_idxs:\n",
    "            len_val_class_error_idx.append(len(i))\n",
    "\n",
    "        least_val_acc_class = len_val_class_error_idx.index(max(len_val_class_error_idx))\n",
    "\n",
    "        print('Class with most misclassified examples is - ', least_val_acc_class)\n",
    "        \n",
    "        for i in range(len(val_class_err_idxs)):\n",
    "            if i == least_val_acc_class:\n",
    "                miscls_idx += list(val_class_err_idxs[least_val_acc_class])\n",
    "        else:\n",
    "            val_class_err_idxs[i] = set()\n",
    "        \n",
    "        print(miscls_idx)        \n",
    "\n",
    "    elif(miscls):\n",
    "        for i in range(len(val_class_err_idxs)):\n",
    "            if i in imb_cls_idx:\n",
    "                miscls_idx += val_class_err_idxs[i]\n",
    "        print(\"Total misclassified examples from imbalanced classes (Size of query set): \", len(miscls_idx))\n",
    "    else:\n",
    "        for i in imb_cls_idx:\n",
    "            imb_cls_samples = list(torch.where(torch.Tensor(val_set.targets.float()) == i)[0].cpu().numpy())\n",
    "            miscls_idx += imb_cls_samples\n",
    "        print(\"Total samples from imbalanced classes as targets (Size of query set): \", len(miscls_idx))\n",
    "    \n",
    "    return Subset(val_set, miscls_idx), val_set.targets[miscls_idx]\n",
    "\n",
    "def getPerClassSel(lake_set, subset, num_cls):\n",
    "    perClsSel = []\n",
    "    if str(type(lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        subset_cls = torch.Tensor(lake_set.targets.astype(np.float))[subset]\n",
    "    else:\n",
    "        subset_cls = torch.Tensor(lake_set.targets.float())[subset]\n",
    "    for i in range(num_cls):\n",
    "        cls_subset_idx = list(torch.where(subset_cls == i)[0].cpu().numpy())\n",
    "        perClsSel.append(len(cls_subset_idx))\n",
    "    return perClsSel\n",
    "\n",
    "def print_final_results(res_dict, sel_cls_idx):\n",
    "    print(\"Gain in overall test accuracy: \", res_dict['test_acc'][1]-res_dict['test_acc'][0])\n",
    "    bf_sel_cls_acc = np.array(res_dict['all_class_acc'][0])[sel_cls_idx]\n",
    "    af_sel_cls_acc = np.array(res_dict['all_class_acc'][1])[sel_cls_idx]\n",
    "    print(\"Gain in targeted test accuracy: \", np.mean(af_sel_cls_acc-bf_sel_cls_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d02859f"
   },
   "source": [
    "# Data, Model & Experimental Settings\n",
    "The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. The training set contains 50,000 images and test set contains 10,000 images. We will use custom_dataset() function in Trust to simulated a class imbalance scenario using the split_cfg dictionary given below. We then use a ResNet18 model as our task DNN and train it on the simulated imbalanced version of the CIFAR-10 dataset. Next we perform targeted selection using various SMI functions and compare their gain in overall accuracy as well as on the imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96ce679b",
    "outputId": "e21e7138-ca97-469b-ae96-a44ebc3f3a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_cfg: {'num_cls_imbalance': 5, 'sel_cls_idx': [0, 1, 2, 3, 4], 'per_imbclass_train': {0: 349, 1: 62, 2: 188, 3: 27, 4: 47}, 'per_imbclass_val': {0: 0, 1: 0, 2: 0, 3: 20, 4: 20}, 'per_imbclass_lake': {0: 1398, 1: 250, 2: 753, 3: 88, 4: 170}, 'per_imbclass_test': {0: 58, 1: 58, 2: 58, 3: 58, 4: 58}}\n"
     ]
    }
   ],
   "source": [
    "feature = \"longtail\"\n",
    "device_id = 1\n",
    "run=\"exp_5_1\"\n",
    "datadir = 'aptos_data/'\n",
    "data_name = 'aptos'\n",
    "model_name = 'ResNet18'\n",
    "learning_rate = 0.0003\n",
    "computeClassErrorLog = True\n",
    "device = \"cuda:\"+str(device_id) if torch.cuda.is_available() else \"cpu\"\n",
    "#Set miscls to 'target' to target only class with most misclassified examples\n",
    "#Set to True if only the misclassified examples from the imbalanced classes is to be used\n",
    "miscls = 'target'\n",
    "embedding_type = \"gradients\" #Type of the representation to use (gradients/features)\n",
    "num_cls = 5\n",
    "budget = 20\n",
    "visualize_tsne = False\n",
    "tns = [] #train_num_samples\n",
    "imbf = 60 #imbalance factor\n",
    "import math\n",
    "for i in range(1,num_cls+1):\n",
    "    tns.append(math.ceil(5*(1.4**i)))\n",
    "# split_cfg = {\"num_cls_imbalance\":1,\n",
    "#              \"sel_cls_idx\":[0,1,2,3,4,5,6,7,8],\n",
    "#              \"per_imbclass_train\":{0:tns[0],1:tns[1],2:tns[2],3:tns[3],4:tns[4],5:tns[5],6:tns[6],7:tns[7],8:tns[8]},\n",
    "#              \"per_imbclass_val\":{0:10,1:10,2:10,3:10,4:10,5:10,6:10,7:10,8:10},\n",
    "#              \"per_imbclass_lake\":{0:tns[0]*imbf,1:tns[1]*imbf,2:tns[2]*imbf,3:tns[3]*imbf,4:tns[4]*imbf,5:tns[5]*imbf,6:tns[6]*imbf,7:tns[7]*imbf,8:tns[8]*imbf},\n",
    "#             } #cifar10\n",
    "split_cfg = {\"num_cls_imbalance\":5, # This is not used for longtail\n",
    "             \"sel_cls_idx\":[0,1,2,3,4],\n",
    "             # Number of images available combined for train + lake + val are as follows\n",
    "             #  0       1       2       3       4\n",
    "             #  1747    312     941     135     237\n",
    "             \"per_imbclass_train\":{0:349,1:62,2:188,3:27,4:47},\n",
    "             \"per_imbclass_val\":{0:0,1:0,2:0,3:20,4:20},\n",
    "             \"per_imbclass_lake\":{0:1398,1:250,2:753,3:88,4:170},\n",
    "             \"per_imbclass_test\":{0:58,1:58,2:58,3:58,4:58}}\n",
    "print(\"split_cfg:\",split_cfg)\n",
    "initModelPath = \"./\"+data_name + \"_\" + model_name + \"_\" + str(learning_rate) + \"_\" + str(split_cfg[\"num_cls_imbalance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6d2a173"
   },
   "source": [
    "# Targeted Selection Algorithm\n",
    "1. Given: Initial Labeled set of Examples: 𝐸, large unlabeled dataset: 𝑈, A target subset/slice where we want to improve accuracy: 𝑇, Loss function 𝐿 for learning\n",
    "2. Train model with loss $\\mathcal L$ on labeled set $E$ and obtain parameters $\\theta_E$\n",
    "3. Compute the gradients $\\{\\nabla_{\\theta_E} \\mathcal L(x_i, y_i), i \\in U\\}$ (using hypothesized labels) and $\\{\\nabla_{\\theta_E} \\mathcal L(x_i, y_i), i \\in T\\}$. \n",
    "(This notebook uses gradients for representation. However, any other representation can be used. Trust also supports using features via the API.)\n",
    "4. Compute the similarity kernels $S$ (this includes kernel of the elements within $U$, within $T$ and between $U$ and $T$) and define a submodular function $f$ and diversity function $g$\n",
    "5. Compute subset $\\hat{A}$ by mazximizing the SMI function: $\\hat{A} \\gets \\max_{A \\subseteq U, |A|\\leq k} I_f(A;T) + \\gamma g(A)$\n",
    "6. Obtain the labels of the elements in $A^*$: $L(\\hat{A})$\n",
    "7. Train a model on the combined labeled set $E \\cup L(\\hat{A})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "91b510c9"
   },
   "outputs": [],
   "source": [
    "def run_targeted_selection(dataset_name, datadir, feature, model_name, budget, split_cfg, learning_rate, run,\n",
    "                device, computeErrorLog, strategy=\"SIM\", sf=\"\"):\n",
    "\n",
    "    #load the dataset in the class imbalance setting\n",
    "    train_set, val_set, test_set, lake_set, sel_cls_idx, num_cls = load_biodataset_custom(datadir, dataset_name, feature, split_cfg, False, False)\n",
    "    print(\"Indices of randomly selected classes for imbalance: \", sel_cls_idx)\n",
    "    \n",
    "    #Set batch size for train, validation and test datasets\n",
    "    N = len(train_set)\n",
    "    trn_batch_size = 20\n",
    "    val_batch_size = 10\n",
    "    tst_batch_size = 100\n",
    "\n",
    "    #Create dataloaders\n",
    "    trainloader = torch.utils.data.DataLoader(train_set, batch_size=trn_batch_size,\n",
    "                                              shuffle=True, pin_memory=True)\n",
    "\n",
    "    valloader = torch.utils.data.DataLoader(val_set, batch_size=val_batch_size, \n",
    "                                            shuffle=False, pin_memory=True)\n",
    "\n",
    "    tstloader = torch.utils.data.DataLoader(test_set, batch_size=tst_batch_size,\n",
    "                                             shuffle=False, pin_memory=True)\n",
    "    \n",
    "    lakeloader = torch.utils.data.DataLoader(lake_set, batch_size=tst_batch_size,\n",
    "                                         shuffle=False, pin_memory=True)\n",
    "    true_lake_set = copy.deepcopy(lake_set)\n",
    "    # Budget for subset selection\n",
    "    bud = budget\n",
    "   \n",
    "    # Variables to store accuracies\n",
    "    num_rounds=10 #The first round is for training the initial model and the second round is to train the final model\n",
    "    fulltrn_losses = np.zeros(num_rounds)\n",
    "    val_losses = np.zeros(num_rounds)\n",
    "    tst_losses = np.zeros(num_rounds)\n",
    "    timing = np.zeros(num_rounds)\n",
    "    val_acc = np.zeros(num_rounds)\n",
    "    full_trn_acc = np.zeros(num_rounds)\n",
    "    tst_acc = np.zeros(num_rounds)\n",
    "    final_tst_predictions = []\n",
    "    final_tst_classifications = []\n",
    "    best_val_acc = -1\n",
    "    csvlog = []\n",
    "    val_csvlog = []\n",
    "    # Results logging file\n",
    "    all_logs_dir = './results/' + dataset_name  + '/' + feature + '/'+  sf + '/' + str(bud) + '/' + str(run)\n",
    "    print(\"Saving results to: \", all_logs_dir)\n",
    "    subprocess.run([\"mkdir\", \"-p\", all_logs_dir]) #Uncomment for saving results\n",
    "    exp_name = dataset_name + \"_\" + feature +  \"_\" + strategy + \"_\" + str(len(sel_cls_idx))  +\"_\" + sf +  '_budget:' + str(bud) + '_rounds:' + str(num_rounds) + '_runs' + str(run)\n",
    "\n",
    "    #Create a dictionary for storing results and the experimental setting\n",
    "    res_dict = {\"dataset\":data_name, \n",
    "                \"feature\":feature, \n",
    "                \"sel_func\":sf,\n",
    "                \"sel_budget\":budget, \n",
    "                \"num_selections\":num_rounds-1, \n",
    "                \"model\":model_name, \n",
    "                \"learning_rate\":learning_rate, \n",
    "                \"setting\":split_cfg, \n",
    "                \"all_class_acc\":None, \n",
    "                \"test_acc\":[],\n",
    "                \"sel_per_cls\":[], \n",
    "                \"sel_cls_idx\":sel_cls_idx}\n",
    "    \n",
    "    # Model Creation\n",
    "    model = create_model(model_name, num_cls, device, embedding_type)\n",
    "    model1 = create_model(model_name, num_cls, device, embedding_type)\n",
    "    strategy_args = {'batch_size': 20, 'device':device, 'embedding_type':'gradients', 'keep_embedding':True}\n",
    "    unlabeled_lake_set = LabeledToUnlabeledDataset(lake_set)\n",
    "    \n",
    "    if(strategy == \"AL\"):\n",
    "        if(sf==\"badge\"):\n",
    "            strategy_sel = BADGE(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"us\"):\n",
    "            strategy_sel = EntropySampling(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"glister\" or sf==\"glister-tss\"):\n",
    "            strategy_sel = GLISTER(train_set, unlabeled_lake_set, model, num_cls, strategy_args, val_set, typeOf='rand', lam=0.1)\n",
    "        elif(sf==\"gradmatch-tss\"):\n",
    "            strategy_sel = GradMatchActive(train_set, unlabeled_lake_set, model, num_cls, strategy_args, val_set)\n",
    "        elif(sf==\"coreset\"):\n",
    "            strategy_sel = CoreSet(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"leastconf\"):\n",
    "            strategy_sel = LeastConfidence(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"margin\"):\n",
    "            strategy_sel = MarginSampling(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "    if(strategy == \"SIM\"):\n",
    "        strategy_args['smi_function'] = sf\n",
    "        strategy_sel = SMI(train_set, unlabeled_lake_set, val_set, model, num_cls, strategy_args)\n",
    "    if(strategy == \"random\"):\n",
    "        strategy_sel = RandomSampling(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        \n",
    "    # Loss Functions\n",
    "    criterion, criterion_nored = loss_function()\n",
    "\n",
    "    # Getting the optimizer and scheduler\n",
    "    optimizer = optimizer_without_scheduler(model, learning_rate)\n",
    "\n",
    "    for i in range(num_rounds):\n",
    "        tst_loss = 0\n",
    "        tst_correct = 0\n",
    "        tst_total = 0\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        if(i==0):\n",
    "            print(\"Initial training epoch\")\n",
    "            if(os.path.exists(initModelPath)): #Read the initial trained model if it exists\n",
    "                model.load_state_dict(torch.load(initModelPath, map_location=device))\n",
    "                print(\"Init model loaded from disk, skipping init training: \", initModelPath)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    final_val_predictions = []\n",
    "                    final_val_classifications = []\n",
    "                    for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "                        inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        val_loss += loss.item()\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        val_total += targets.size(0)\n",
    "                        val_correct += predicted.eq(targets).sum().item()\n",
    "                        final_val_predictions += list(predicted.cpu().numpy())\n",
    "                        final_val_classifications += list(predicted.eq(targets).cpu().numpy())\n",
    "  \n",
    "                    final_tst_predictions = []\n",
    "                    final_tst_classifications = []\n",
    "                    for batch_idx, (inputs, targets) in enumerate(tstloader):\n",
    "                        inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        tst_loss += loss.item()\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        tst_total += targets.size(0)\n",
    "                        tst_correct += predicted.eq(targets).sum().item()\n",
    "                        final_tst_predictions += list(predicted.cpu().numpy())\n",
    "                        final_tst_classifications += list(predicted.eq(targets).cpu().numpy())                \n",
    "                    best_val_acc = (val_correct/val_total)\n",
    "                    val_acc[i] = val_correct / val_total\n",
    "                    tst_acc[i] = tst_correct / tst_total\n",
    "                    val_losses[i] = val_loss\n",
    "                    tst_losses[i] = tst_loss\n",
    "                    res_dict[\"test_acc\"].append(tst_acc[i]*100)\n",
    "                continue\n",
    "        else:\n",
    "            #Remove true labels from the unlabeled dataset, the hypothesized labels are computed when select is called\n",
    "            unlabeled_lake_set = LabeledToUnlabeledDataset(lake_set)\n",
    "            strategy_sel.update_data(train_set, unlabeled_lake_set)\n",
    "            #compute the error log before every selection\n",
    "            if(computeErrorLog):\n",
    "                tst_err_log, val_err_log, val_class_err_idxs = find_err_per_class(test_set, val_set, final_val_classifications, final_val_predictions, final_tst_classifications, final_tst_predictions, all_logs_dir, sf+\"_\"+str(bud))\n",
    "                csvlog.append([100-x for x in tst_err_log])\n",
    "                val_csvlog.append([100-x for x in val_err_log])\n",
    "            ####SIM####\n",
    "            if(strategy==\"SIM\" or strategy==\"SF\"):\n",
    "                if(sf.endswith(\"mi\")):\n",
    "                    if(feature==\"classimb\" or feature==\"longtail\"):\n",
    "                        #make a dataloader for the misclassifications - only for experiments with targets\n",
    "                        miscls_set, miscls_set_targets = getQuerySet(val_set, val_class_err_idxs, sel_cls_idx, miscls)                        \n",
    "                        strategy_sel.update_queries(miscls_set)                  \n",
    "            elif(strategy==\"AL\"):\n",
    "                if(sf==\"glister-tss\" or sf==\"gradmatch-tss\"):\n",
    "                    miscls_set = getQuerySet(val_set, val_class_err_idxs, sel_cls_idx, miscls)\n",
    "                    strategy_sel.update_queries(miscls_set)\n",
    "                    print(\"reinit AL with targeted miscls samples\")\n",
    "            \n",
    "            strategy_sel.update_model(model)\n",
    "            subset = strategy_sel.select(budget)\n",
    "            print(\"#### Selection Complete, Now re-training with augmented subset ####\")\n",
    "            if(visualize_tsne):\n",
    "                tsne_plt = tsne_smi(strategy_sel.unlabeled_data_embedding.cpu(),\n",
    "                                    lake_set.targets,\n",
    "                                    strategy_sel.query_embedding.cpu(),\n",
    "                                    miscls_set_targets,\n",
    "                                    subset)\n",
    "                print(\"Computed TSNE plot of the selection\")\n",
    "            lake_subset_idxs = subset #indices wrt to lake that need to be removed from the lake\n",
    "            perClsSel = getPerClassSel(true_lake_set, lake_subset_idxs, num_cls)\n",
    "            res_dict['sel_per_cls'].append(perClsSel)\n",
    "            print(\"\\n perClsSel - \", perClsSel)\n",
    "            \n",
    "            #augment the train_set with selected indices from the lake\n",
    "            train_set, lake_set, true_lake_set, add_val_set = aug_train_subset(train_set, lake_set, true_lake_set, subset, lake_subset_idxs, budget, True) #aug train with random if budget is not filled\n",
    "            print(\"After augmentation, size of train_set: \", len(train_set), \" unlabeled set: \", len(lake_set), \" val set: \", len(val_set))\n",
    "            print('\\n Lake Set - ', lake_set.targets)\n",
    "\n",
    "#           Reinit train and lake loaders with new splits and reinit the model\n",
    "            trainloader = torch.utils.data.DataLoader(train_set, batch_size=trn_batch_size, shuffle=True, pin_memory=True)\n",
    "            lakeloader = torch.utils.data.DataLoader(lake_set, batch_size=tst_batch_size, shuffle=False, pin_memory=True)\n",
    "            model = create_model(model_name, num_cls, device, strategy_args['embedding_type'])\n",
    "            optimizer = optimizer_without_scheduler(model, learning_rate)\n",
    "                \n",
    "        #Start training\n",
    "        start_time = time.time()\n",
    "        num_ep=1\n",
    "#         while(num_ep<150):\n",
    "        while(full_trn_acc[i]<0.99 and num_ep<100):\n",
    "            model.train()\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                # Variables in Pytorch are differentiable.\n",
    "                inputs, target = Variable(inputs), Variable(inputs)\n",
    "                # This will zero out the gradients for this batch.\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "#             scheduler.step()\n",
    "          \n",
    "            full_trn_loss = 0\n",
    "            full_trn_correct = 0\n",
    "            full_trn_total = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(trainloader): #Compute Train accuracy\n",
    "                    inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    full_trn_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    full_trn_total += targets.size(0)\n",
    "                    full_trn_correct += predicted.eq(targets).sum().item()\n",
    "                full_trn_acc[i] = full_trn_correct / full_trn_total\n",
    "                print(\"Selection Epoch \", i, \" Training epoch [\" , num_ep, \"]\" , \" Training Acc: \", full_trn_acc[i], end=\"\\r\")\n",
    "                num_ep+=1\n",
    "            timing[i] = time.time() - start_time\n",
    "        with torch.no_grad():\n",
    "            final_val_predictions = []\n",
    "            final_val_classifications = []\n",
    "            for batch_idx, (inputs, targets) in enumerate(valloader): #Compute Val accuracy\n",
    "                inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "                final_val_predictions += list(predicted.cpu().numpy())\n",
    "                final_val_classifications += list(predicted.eq(targets).cpu().numpy())\n",
    "\n",
    "            final_tst_predictions = []\n",
    "            final_tst_classifications = []\n",
    "            for batch_idx, (inputs, targets) in enumerate(tstloader): #Compute test accuracy\n",
    "                inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                tst_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                tst_total += targets.size(0)\n",
    "                tst_correct += predicted.eq(targets).sum().item()\n",
    "                final_tst_predictions += list(predicted.cpu().numpy())\n",
    "                final_tst_classifications += list(predicted.eq(targets).cpu().numpy())                \n",
    "            val_acc[i] = val_correct / val_total\n",
    "            tst_acc[i] = tst_correct / tst_total\n",
    "            val_losses[i] = val_loss\n",
    "            fulltrn_losses[i] = full_trn_loss\n",
    "            tst_losses[i] = tst_loss\n",
    "            full_val_acc = list(np.array(val_acc))\n",
    "            full_timing = list(np.array(timing))\n",
    "            res_dict[\"test_acc\"].append(tst_acc[i]*100)\n",
    "            print('Epoch:', i + 1, 'FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time:', full_trn_loss, full_trn_acc[i], val_loss, val_acc[i], tst_loss, tst_acc[i], timing[i])\n",
    "            print(\"Gain in accuracy: \",res_dict['test_acc'][i]-res_dict['test_acc'][i-1])\n",
    "        if(i==0): \n",
    "            print(\"Saving initial model\") \n",
    "            torch.save(model.state_dict(), initModelPath) #save initial train model if not present\n",
    "            \n",
    "    #Compute the statistics of the final model\n",
    "    if(computeErrorLog):\n",
    "        print(\"**** Final Metrics after Targeted Learning ****\")\n",
    "        tst_err_log, val_err_log, val_class_err_idxs = find_err_per_class(test_set, val_set, final_val_classifications, final_val_predictions, final_tst_classifications, final_tst_predictions, all_logs_dir, sf+\"_\"+str(bud))\n",
    "        csvlog.append([100-x for x in tst_err_log])\n",
    "        val_csvlog.append([100-x for x in val_err_log])\n",
    "        res_dict[\"all_class_acc\"] = csvlog\n",
    "        res_dict[\"all_val_class_acc\"] = val_csvlog\n",
    "        \n",
    "    #Print overall acc improvement and rare class acc improvement, show that TL selected relevant points in space, is possible show some images\n",
    "#     print_final_results(res_dict, sel_cls_idx)\n",
    "    print(\"Total gain in accuracy: \",res_dict['test_acc'][i]-res_dict['test_acc'][0])\n",
    "    \n",
    "    #save results dir with test acc and per class selections\n",
    "    with open(os.path.join(all_logs_dir, exp_name+\".json\"), 'w') as fp:\n",
    "        json.dump(res_dict, fp)\n",
    "    \n",
    "#     tsne_plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.monotonic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3240bc93"
   },
   "source": [
    "# Submodular Mutual Information (SMI)\n",
    "\n",
    "We let $V$ denote the ground-set of $n$ data points $V = \\{1, 2, 3,...,n \\}$ and a set function $f:\n",
    " 2^{V} \\xrightarrow{} \\Re$. Given a set of items $A, B \\subseteq V$, the submodular mutual information (MI)[1,3] is defined as $I_f(A; B) = f(A) + f(B) - f(A \\cup B)$. Intuitively, this measures the similarity between $B$ and $A$ and we refer to $B$ as the query set.\n",
    "\n",
    "In [2], they extend MI to handle the case when the target can come from an auxiliary set $V^{\\prime}$ different from the ground set $V$. For targeted data subset selection, $V$ is the source set of data instances and the target is a subset of data points (validation set or the specific set of examples of interest).\n",
    "Let $\\Omega  = V \\cup V^{\\prime}$. We define a set function $f: 2^{\\Omega} \\rightarrow \\Re$. Although $f$ is defined on $\\Omega$, the discrete optimization problem will only be defined on subsets $A \\subseteq V$. To find an optimal subset given a query set $Q \\subseteq V^{\\prime}$, we can define $g_{Q}(A) = I_f(A; Q)$, $A \\subseteq V$ and maximize the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c3045e5"
   },
   "source": [
    "# FL1MI\n",
    "\n",
    "In the first variant of FL, we set the unlabeled dataset to be $V$. The SMI instantiation of FL1MI can be defined as:\n",
    "\\begin{align}\n",
    "I_f(A;Q)=\\sum_{i \\in V}\\min(\\max_{j \\in A}s_{ij}, \\eta \\max_{j \\in Q}sq_{ij})\n",
    "\\end{align}\n",
    "\n",
    "The first term in the min(.) of FL1MI models diversity, and the second term models query relevance. An increase in the value of $\\eta$ causes the resulting summary to become more relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a96a686",
    "outputId": "726a587e-79f9-42a7-8910-f86b718eb651",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/fl1mi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 0, 4, 0, 14]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.2733873203396797 0.9927849927849928 10.783345699310303 0.075 5.406487703323364 0.4206896551724138 50.05728340148926\n",
      "Gain in accuracy:  3.7931034482758648\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           27.59 |\n",
      "|       2 |            100 |           65.52 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |             10 |           20.69 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "27.590000000000003\n",
      "65.52000000000001\n",
      "0.0\n",
      "20.689999999999998\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 33, 34, 35, 36, 37, 38, 39, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [1, 2, 5, 1, 11]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.5528854951262474 0.9901823281907434 11.190627813339233 0.125 5.727946162223816 0.4 57.87924575805664\n",
      "Gain in accuracy:  -2.068965517241381\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           13.79 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |             20 |           15.52 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "13.790000000000006\n",
      "70.69\n",
      "3.450000000000003\n",
      "15.519999999999996\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 34, 35, 36, 38, 39, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [5, 0, 6, 0, 9]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.8867456637090072 0.990450204638472 15.860306978225708 0.1 7.341955304145813 0.4068965517241379 200.2654755115509\n",
      "Gain in accuracy:  0.6896551724137936\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           89.66 |\n",
      "|       1 |            100 |           32.76 |\n",
      "|       2 |            100 |           65.52 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |             15 |           15.52 |\n",
      "Test accuracy is as follows - \n",
      "89.66\n",
      "32.760000000000005\n",
      "65.52000000000001\n",
      "0.0\n",
      "15.519999999999996\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 33, 34, 35, 37, 38, 39, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 1, 6, 2, 8]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.8228049472672865 0.9893758300132802 15.736289978027344 0.1 7.44150710105896 0.4241379310344828 291.6495215892792\n",
      "Gain in accuracy:  1.724137931034484\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           93.1  |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |             15 |           13.79 |\n",
      "Test accuracy is as follows - \n",
      "93.1\n",
      "24.14\n",
      "79.31\n",
      "1.7199999999999989\n",
      "13.790000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 33, 34, 35, 37, 38, 39, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 1, 1, 1, 17]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.9411748991697095 0.9883570504527813 12.739492177963257 0.175 6.92062520980835 0.39655172413793105 311.44219422340393\n",
      "Gain in accuracy:  -2.7586206896551744\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           20.69 |\n",
      "|       2 |            100 |           51.72 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |             30 |           31.03 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "20.689999999999998\n",
      "51.72\n",
      "0.0\n",
      "31.03\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 33, 34, 35, 37, 38, 39, 20, 21, 22, 24, 26, 28, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 0, 7, 0, 10]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.0817068653414026 0.9886506935687264 12.948612332344055 0.175 7.388387084007263 0.39655172413793105 323.2388451099396\n",
      "Gain in accuracy:  0.0\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           18.97 |\n",
      "|       2 |            100 |           51.72 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |             30 |           29.31 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "18.97\n",
      "51.72\n",
      "3.450000000000003\n",
      "29.310000000000002\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 33, 34, 35, 37, 38, 39, 20, 21, 22, 24, 25, 30, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 0, 6, 0, 10]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.0120181444799528 0.990159901599016 15.790238857269287 0.15 7.5897709131240845 0.42758620689655175 202.40064239501953\n",
      "Gain in accuracy:  3.103448275862071\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           13.79 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |             25 |           27.59 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "13.790000000000006\n",
      "77.59\n",
      "0.0\n",
      "27.590000000000003\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 34, 35, 37, 38, 39, 20, 21, 22, 24, 25, 26, 29, 30, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 1, 2, 1, 14]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.987859356449917 0.9879951980792316 16.055552005767822 0.125 7.435615301132202 0.42758620689655175 348.80395436286926\n",
      "Gain in accuracy:  0.0\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           32.76 |\n",
      "|       2 |            100 |           68.97 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |             20 |           12.07 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "32.760000000000005\n",
      "68.97\n",
      "3.450000000000003\n",
      "12.069999999999993\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 34, 35, 36, 37, 38, 39, 20, 21, 22, 23, 24, 26, 28, 30, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 1, 4, 0, 12]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.0958507384639233 0.9882766705744431 15.49695611000061 0.15 7.257399201393127 0.4241379310344828 358.8755669593811\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           17.24 |\n",
      "|       2 |            100 |           68.97 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |             25 |           27.59 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "17.239999999999995\n",
      "68.97\n",
      "3.450000000000003\n",
      "27.590000000000003\n",
      "Total gain in accuracy:  4.137931034482762\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"SIM\",'fl1mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b1fc84e"
   },
   "source": [
    "# FL2MI\n",
    "\n",
    "In the V2 variant, we set $D$ to be $V \\cup Q$. The SMI instantiation of FL2MI can be defined as:\n",
    "\\begin{align} \\label{eq:FL2MI}\n",
    "I_f(A;Q)=\\sum_{i \\in Q} \\max_{j \\in A} sq_{ij} + \\eta\\sum_{i \\in A} \\max_{j \\in Q} sq_{ij}\n",
    "\\end{align}\n",
    "FL2MI is very intuitive for query relevance as well. It measures the representation of data points that are the most relevant to the query set and vice versa. It can also be thought of as a bidirectional representation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1e29177",
    "outputId": "7db4433a-368a-46d0-ea95-932be07ecd46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/fl2mi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [5, 0, 9, 0, 6]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.757520267739892 0.9927849927849928 11.683455228805542 0.05 5.71949315071106 0.4103448275862069 57.04423475265503\n",
      "Gain in accuracy:  2.7586206896551744\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           20.69 |\n",
      "|       2 |            100 |           72.41 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              5 |           13.79 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "20.689999999999998\n",
      "72.41\n",
      "1.7199999999999989\n",
      "13.790000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 5, 12, 1, 2]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.906110021402128 0.9859747545582047 17.165955066680908 0.05 8.011905550956726 0.42758620689655175 293.8524646759033\n",
      "Gain in accuracy:  1.724137931034484\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           41.38 |\n",
      "|       2 |            100 |           68.97 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "41.38\n",
      "68.97\n",
      "1.7199999999999989\n",
      "6.900000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [5, 0, 7, 2, 6]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.0079314834438264 0.9863574351978172 15.504865407943726 0.05 7.686531066894531 0.40344827586206894 289.82457208633423\n",
      "Gain in accuracy:  -2.4137931034482776\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           93.1  |\n",
      "|       1 |            100 |           31.03 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |              5 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "93.1\n",
      "31.03\n",
      "70.69\n",
      "3.450000000000003\n",
      "3.450000000000003\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 6, 8, 2, 2]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.065656946389936 0.9853917662682603 16.181050539016724 0.05 8.203383803367615 0.38620689655172413 299.0790915489197\n",
      "Gain in accuracy:  -1.724137931034484\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           93.1  |\n",
      "|       1 |            100 |           17.24 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              5 |            6.9  |\n",
      "|       4 |              5 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "93.1\n",
      "17.239999999999995\n",
      "74.14\n",
      "6.900000000000006\n",
      "1.7199999999999989\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 3, 8, 3, 2]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.8827890902757645 0.9870633893919794 17.246992111206055 0.05 7.709630131721497 0.4241379310344828 316.77964520454407\n",
      "Gain in accuracy:  3.7931034482758648\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           32.76 |\n",
      "|       2 |            100 |           72.41 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |              5 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "32.760000000000005\n",
      "72.41\n",
      "3.450000000000003\n",
      "8.620000000000005\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 4, 10, 3, 1]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.92556313512614 0.9886506935687264 17.596028327941895 0.025 8.398487210273743 0.4206896551724138 325.63772916793823\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           27.59 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              5 |            8.62 |\n",
      "|       4 |              0 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "27.590000000000003\n",
      "74.14\n",
      "8.620000000000005\n",
      "5.170000000000002\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 2, 10, 2, 3]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.1417520639952272 0.986469864698647 18.779502391815186 0.075 8.110520005226135 0.4206896551724138 341.43692445755005\n",
      "Gain in accuracy:  0.0\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           29.31 |\n",
      "|       2 |            100 |           75.86 |\n",
      "|       3 |             10 |            3.45 |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "29.310000000000002\n",
      "75.86\n",
      "3.450000000000003\n",
      "6.900000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 4, 10, 2, 2]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.076894978294149 0.985594237695078 18.74948740005493 0.05 8.100828647613525 0.46206896551724136 360.3189651966095\n",
      "Gain in accuracy:  4.1379310344827545\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           31.03 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |             10 |           13.79 |\n",
      "|       4 |              0 |           12.07 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "31.03\n",
      "79.31\n",
      "13.790000000000006\n",
      "12.069999999999993\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 7, 5, 2, 6]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.2257584049948491 0.9859320046893317 17.378232955932617 0.05 7.991047739982605 0.4379310344827586 407.3107373714447\n",
      "Gain in accuracy:  -2.4137931034482776\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |             10 |           10.34 |\n",
      "|       4 |              0 |           12.07 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "77.59\n",
      "10.340000000000003\n",
      "12.069999999999993\n",
      "Total gain in accuracy:  5.517241379310342\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog, \n",
    "               \"SIM\",'fl2mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "330ea94d"
   },
   "source": [
    "# GCMI\n",
    "\n",
    "The SMI instantiation of graph-cut (GCMI) is defined as:\n",
    "\\begin{align}\n",
    "I_f(A;Q)=2\\sum_{i \\in A} \\sum_{j \\in Q} sq_{ij}\n",
    "\\end{align}\n",
    "Since maximizing GCMI maximizes the joint pairwise sum with the query set, it will lead to a subset similar to the query set $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dc6e91d",
    "outputId": "a5140e1d-1c48-4882-a595-ee71c04d17e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/gcmi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [5, 0, 9, 0, 6]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.2868538685142994 0.9927849927849928 11.272039890289307 0.075 5.604573130607605 0.4 107.56835770606995\n",
      "Gain in accuracy:  1.724137931034484\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           22.41 |\n",
      "|       2 |            100 |           68.97 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |             10 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "22.409999999999997\n",
      "68.97\n",
      "3.450000000000003\n",
      "8.620000000000005\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {32, 33, 34, 35, 36, 37, 38, 39, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 2, 16, 0, 0]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.844766691327095 0.9901823281907434 10.972636938095093 0.025 5.587667107582092 0.4206896551724138 117.05766487121582\n",
      "Gain in accuracy:  2.068965517241381\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           25.86 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |              5 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "25.86\n",
      "79.31\n",
      "0.0\n",
      "8.620000000000005\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [7, 1, 5, 4, 3]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 0.8855455102748238 0.9863574351978172 15.552751302719116 0.05 7.207268595695496 0.45517241379310347 490.02429246902466\n",
      "Gain in accuracy:  3.448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           34.48 |\n",
      "|       2 |            100 |           67.24 |\n",
      "|       3 |             10 |            8.62 |\n",
      "|       4 |              0 |           20.69 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "34.480000000000004\n",
      "67.24000000000001\n",
      "8.620000000000005\n",
      "20.689999999999998\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 2, 10, 5, 3]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.1831350396969356 0.9867197875166003 16.618600606918335 0.025 7.526752471923828 0.43448275862068964 589.3650794029236\n",
      "Gain in accuracy:  -2.068965517241388\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           32.76 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              5 |            6.9  |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "32.760000000000005\n",
      "77.59\n",
      "6.900000000000006\n",
      "3.450000000000003\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 4, 12, 2, 2]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.1181370028061792 0.9844760672703752 14.276570320129395 0.05 7.047777533531189 0.42758620689655175 615.1438541412354\n",
      "Gain in accuracy:  -0.6896551724137865\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           31.03 |\n",
      "|       2 |            100 |           75.86 |\n",
      "|       3 |              5 |            5.17 |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "31.03\n",
      "75.86\n",
      "5.170000000000002\n",
      "6.900000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 4, 7, 3, 3]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.1947702341713011 0.9848675914249685 18.609163761138916 0.025 7.655451059341431 0.4379310344827586 646.898943901062\n",
      "Gain in accuracy:  1.0344827586206833\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           37.93 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |              0 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "37.93\n",
      "74.14\n",
      "3.450000000000003\n",
      "8.620000000000005\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 2, 8, 2, 5]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.2635092231212184 0.986469864698647 16.547343730926514 0.075 7.907567501068115 0.43448275862068964 654.3895196914673\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           20.69 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |             10 |            8.62 |\n",
      "|       4 |              5 |           13.79 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "20.689999999999998\n",
      "79.31\n",
      "8.620000000000005\n",
      "13.790000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 3, 9, 2, 3]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.2890277991537005 0.9831932773109243 17.15632152557373 0.075 7.781416654586792 0.4206896551724138 656.6150510311127\n",
      "Gain in accuracy:  -1.37931034482758\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           13.79 |\n",
      "|       2 |            100 |           75.86 |\n",
      "|       3 |             10 |            6.9  |\n",
      "|       4 |              5 |           18.97 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "13.790000000000006\n",
      "75.86\n",
      "6.900000000000006\n",
      "18.97\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 3, 11, 3, 1]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 1.5713225551880896 0.9824150058616647 18.67730474472046 0.025 8.590555191040039 0.4413793103448276 697.294953584671\n",
      "Gain in accuracy:  2.068965517241381\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           20.69 |\n",
      "|       2 |            100 |           82.76 |\n",
      "|       3 |              5 |            6.9  |\n",
      "|       4 |              0 |           15.52 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "20.689999999999998\n",
      "82.76\n",
      "6.900000000000006\n",
      "15.519999999999996\n",
      "Total gain in accuracy:  5.8620689655172455\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"SIM\",'gcmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07323a40"
   },
   "source": [
    "# LOGDETMI\n",
    "\n",
    "The SMI instantiation of LogDetMI can be defined as:\n",
    "\\begin{align}\n",
    "I_f(A;Q)=\\log\\det(S_{A}) -\\log\\det(S_{A} - \\eta^2 S_{A,Q}S_{Q}^{-1}S_{A,Q}^T)\n",
    "\\end{align}\n",
    "$S_{A, B}$ denotes the cross-similarity matrix between the items in sets $A$ and $B$. The similarity matrix in constructed in such a way that the cross-similarity between $A$ and $Q$ is multiplied by $\\eta$ to control the trade-off between query-relevance and diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02ad455b",
    "outputId": "32f1d0bb-f3dc-48c0-e273-9efc159d101a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/logdetmi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 4, 10, 1, 5]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.460983734577894 0.9942279942279942 10.584975481033325 0.025 5.126550614833832 0.4103448275862069 82.84777736663818\n",
      "Gain in accuracy:  2.7586206896551744\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           25.86 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              0 |           12.07 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "25.86\n",
      "70.69\n",
      "1.7199999999999989\n",
      "12.069999999999993\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 4, 11, 2, 0]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.4633642714470625 0.9929873772791024 10.976518154144287 0.05 5.369396090507507 0.4068965517241379 84.58175134658813\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           20.69 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "20.689999999999998\n",
      "77.59\n",
      "1.7199999999999989\n",
      "6.900000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 3, 10, 2, 2]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.948892641812563 0.9918144611186903 12.91003680229187 0.05 5.329752862453461 0.42758620689655175 94.28592228889465\n",
      "Gain in accuracy:  2.068965517241381\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           36.21 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "36.21\n",
      "74.14\n",
      "0.0\n",
      "6.900000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 4, 12, 2, 2]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.2199969813227654 0.9907038512616202 15.231749057769775 0.025 6.558314800262451 0.4 120.38566255569458\n",
      "Gain in accuracy:  -2.7586206896551744\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           15.52 |\n",
      "|       2 |            100 |           86.21 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "15.519999999999996\n",
      "86.21000000000001\n",
      "0.0\n",
      "3.450000000000003\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [1, 3, 12, 2, 2]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.1493103317916393 0.9909443725743855 12.986953735351562 0.025 6.118030667304993 0.4068965517241379 126.79270386695862\n",
      "Gain in accuracy:  0.6896551724137936\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           25.86 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              0 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "25.86\n",
      "74.14\n",
      "1.7199999999999989\n",
      "6.900000000000006\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 5, 9, 3, 1]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.569885527715087 0.9911727616645649 12.398319721221924 0.0 5.807505905628204 0.4206896551724138 116.69302415847778\n",
      "Gain in accuracy:  1.3793103448275872\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           31.03 |\n",
      "|       2 |            100 |           72.41 |\n",
      "|       3 |              0 |            1.72 |\n",
      "|       4 |              0 |           10.34 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "31.03\n",
      "72.41\n",
      "1.7199999999999989\n",
      "10.340000000000003\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 2, 11, 2, 2]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.473950708284974 0.992619926199262 14.257019996643066 0.025 5.670181393623352 0.4482758620689655 118.62371277809143\n",
      "Gain in accuracy:  2.7586206896551744\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           98.28 |\n",
      "|       1 |            100 |           36.21 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              5 |            5.17 |\n",
      "|       4 |              0 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "98.28\n",
      "36.21\n",
      "79.31\n",
      "5.170000000000002\n",
      "5.170000000000002\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  4\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [6, 5, 7, 1, 1]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.1159859728068113 0.9903961584633854 12.574535608291626 0.0 5.696499764919281 0.42758620689655175 113.71777606010437\n",
      "Gain in accuracy:  -2.068965517241381\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           98.28 |\n",
      "|       1 |            100 |           29.31 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              0 |            3.45 |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "98.28\n",
      "29.310000000000002\n",
      "79.31\n",
      "3.450000000000003\n",
      "3.450000000000003\n",
      "\n",
      " val_class_err_idxs -  [set(), set(), set(), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39}]\n",
      "Class with most misclassified examples is -  3\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 5, 9, 1, 1]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.292482916265726 0.9917936694021102 12.07985544204712 0.0 5.962930917739868 0.4 116.52486252784729\n",
      "Gain in accuracy:  -2.7586206896551744\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              0 |            3.45 |\n",
      "|       4 |              0 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "24.14\n",
      "70.69\n",
      "3.450000000000003\n",
      "5.170000000000002\n",
      "Total gain in accuracy:  1.724137931034484\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"SIM\",'logdetmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1ec7d2d"
   },
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9389578a",
    "outputId": "58a78ce2-d769-47d2-9e5c-f3a8dfe8188e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/random/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [10, 4, 5, 0, 1]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.3461292535066605 0.9913419913419913 12.178449392318726 0.025 5.548578143119812 0.41724137931034483 91.32046318054199\n",
      "Gain in accuracy:  3.448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |              5 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "24.14\n",
      "79.31\n",
      "0.0\n",
      "8.620000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [10, 2, 6, 1, 1]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.484644804149866 0.9901823281907434 11.399884939193726 0.0 5.18901515007019 0.4206896551724138 78.55020093917847\n",
      "Gain in accuracy:  0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           34.48 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              0 |            1.72 |\n",
      "|       4 |              0 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "34.480000000000004\n",
      "70.69\n",
      "1.7199999999999989\n",
      "8.620000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [10, 2, 7, 0, 1]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.2949900217354298 0.9931787175989086 11.424710512161255 0.025 5.330138146877289 0.41724137931034483 102.8691976070404\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           31.03 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "31.03\n",
      "77.59\n",
      "0.0\n",
      "3.450000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [9, 2, 6, 1, 2]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.9727182760834694 0.9907038512616202 10.659505128860474 0.05 5.3493510484695435 0.38620689655172413 90.86680507659912\n",
      "Gain in accuracy:  -3.103448275862071\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           68.97 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              5 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "68.97\n",
      "0.0\n",
      "5.170000000000002\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [13, 1, 4, 0, 2]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.4309012144804 0.9922380336351876 11.587774276733398 0.025 5.487639307975769 0.4103448275862069 116.33661389350891\n",
      "Gain in accuracy:  2.4137931034482776\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           29.31 |\n",
      "|       2 |            100 |           67.24 |\n",
      "|       3 |              5 |            5.17 |\n",
      "|       4 |              0 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "29.310000000000002\n",
      "67.24000000000001\n",
      "5.170000000000002\n",
      "6.900000000000006\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [10, 1, 8, 1, 0]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.261978220194578 0.9936948297604036 11.484556436538696 0.05 5.498342752456665 0.41379310344827586 103.37778401374817\n",
      "Gain in accuracy:  0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           27.59 |\n",
      "|       2 |            100 |           72.41 |\n",
      "|       3 |             10 |            1.72 |\n",
      "|       4 |              0 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "27.590000000000003\n",
      "72.41\n",
      "1.7199999999999989\n",
      "8.620000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [12, 2, 2, 1, 3]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.7996792942285538 0.991389913899139 10.985273122787476 0.05 5.162567377090454 0.41379310344827586 109.6650505065918\n",
      "Gain in accuracy:  0.0\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           34.48 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              5 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "34.480000000000004\n",
      "74.14\n",
      "0.0\n",
      "1.7199999999999989\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [10, 3, 7, 0, 0]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.9842340610921383 0.9903961584633854 12.027292251586914 0.025 6.028915047645569 0.41724137931034483 128.02268743515015\n",
      "Gain in accuracy:  0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           25.86 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "25.86\n",
      "77.59\n",
      "0.0\n",
      "8.620000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [12, 2, 5, 0, 1]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.002050813287497 0.9906213364595545 11.854702949523926 0.025 5.547915518283844 0.4103448275862069 107.18160939216614\n",
      "Gain in accuracy:  -0.6896551724137936\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           36.21 |\n",
      "|       2 |            100 |           67.24 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |              5 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "36.21\n",
      "67.24000000000001\n",
      "0.0\n",
      "5.170000000000002\n",
      "Total gain in accuracy:  2.7586206896551744\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"random\",'random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d70fddb5"
   },
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6164c9b4",
    "outputId": "84d3b099-54d2-47d8-e4e7-1227778c17b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/us/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [1, 4, 9, 2, 4]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.433683915063739 0.9956709956709957 11.811760425567627 0.025 5.37152373790741 0.3931034482758621 98.29222464561462\n",
      "Gain in accuracy:  1.0344827586206904\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           18.97 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              0 |           10.34 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "18.97\n",
      "70.69\n",
      "1.7199999999999989\n",
      "10.340000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 1, 8, 6, 2]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.6403563506901264 0.9957924263674615 10.736162424087524 0.05 5.149358034133911 0.42758620689655175 106.51871109008789\n",
      "Gain in accuracy:  3.448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           29.31 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            6.9  |\n",
      "|       4 |              5 |           12.07 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "29.310000000000002\n",
      "70.69\n",
      "6.900000000000006\n",
      "12.069999999999993\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [5, 2, 8, 1, 4]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.2340535297989845 0.9945429740791268 11.712261199951172 0.025 5.634755373001099 0.3931034482758621 98.31017422676086\n",
      "Gain in accuracy:  -3.448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           17.24 |\n",
      "|       2 |            100 |           68.97 |\n",
      "|       3 |              5 |           10.34 |\n",
      "|       4 |              0 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "17.239999999999995\n",
      "68.97\n",
      "10.340000000000003\n",
      "5.170000000000002\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [1, 3, 10, 3, 3]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.050161462277174 0.9907038512616202 11.87289571762085 0.0 5.220315337181091 0.41724137931034483 87.9208755493164\n",
      "Gain in accuracy:  2.4137931034482776\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           87.93 |\n",
      "|       1 |            100 |           27.59 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              0 |           10.34 |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "87.93\n",
      "27.590000000000003\n",
      "79.31\n",
      "10.340000000000003\n",
      "3.450000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 4, 11, 1, 0]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.9283643513917923 0.9909443725743855 11.786946058273315 0.075 5.520851492881775 0.4068965517241379 103.4814305305481\n",
      "Gain in accuracy:  -1.0344827586206904\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |            8.62 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |             10 |           12.07 |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "8.620000000000005\n",
      "79.31\n",
      "12.069999999999993\n",
      "6.900000000000006\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 6, 8, 3, 0]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 2.573873519897461 0.9949558638083228 12.055664300918579 0.025 5.456739664077759 0.4517241379310345 99.86539220809937\n",
      "Gain in accuracy:  4.482758620689658\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           34.48 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              0 |           10.34 |\n",
      "|       4 |              5 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "34.480000000000004\n",
      "79.31\n",
      "10.340000000000003\n",
      "5.170000000000002\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [0, 5, 9, 1, 5]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.100328363478184 0.993849938499385 11.978790998458862 0.025 5.40318375825882 0.44482758620689655 111.35804963111877\n",
      "Gain in accuracy:  -0.6896551724137936\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           36.21 |\n",
      "|       2 |            100 |           75.86 |\n",
      "|       3 |              5 |           10.34 |\n",
      "|       4 |              0 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "36.21\n",
      "75.86\n",
      "10.340000000000003\n",
      "5.170000000000002\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 4, 8, 1, 3]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.0741392001509666 0.9951980792316927 12.413819313049316 0.05 5.566531777381897 0.43103448275862066 110.5886116027832\n",
      "Gain in accuracy:  -1.3793103448275943\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           17.24 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |             10 |           12.07 |\n",
      "|       4 |              0 |           12.07 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "17.239999999999995\n",
      "79.31\n",
      "12.069999999999993\n",
      "12.069999999999993\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 8, 8, 0, 2]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.1859750542789698 0.9953106682297772 12.14764666557312 0.05 5.35652357339859 0.46551724137931033 109.0714864730835\n",
      "Gain in accuracy:  3.448275862068968\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           34.48 |\n",
      "|       2 |            100 |           82.76 |\n",
      "|       3 |              5 |           12.07 |\n",
      "|       4 |              5 |            6.9  |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "34.480000000000004\n",
      "82.76\n",
      "12.069999999999993\n",
      "6.900000000000006\n",
      "Total gain in accuracy:  8.275862068965516\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"AL\",'us')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebc215ed"
   },
   "source": [
    "# BADGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61e524cd",
    "outputId": "37e4d019-520a-4891-94ab-7a01324325b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APTOS Custom dataset stats: Train size:  673 Val size:  40 Lake size:  2659\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4]\n",
      "Saving results to:  ./results/aptos/longtail/badge/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./aptos_ResNet18_0.0003_5\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            1.72 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "24.14\n",
      "70.69\n",
      "0.0\n",
      "1.7199999999999989\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [6, 3, 6, 1, 4]\n",
      "After augmentation, size of train_set:  693  unlabeled set:  2639  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.775483410805464 0.9942279942279942 10.037787199020386 0.05 5.065442740917206 0.4206896551724138 84.9804995059967\n",
      "Gain in accuracy:  3.7931034482758648\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           36.21 |\n",
      "|       2 |            100 |           72.41 |\n",
      "|       3 |              5 |            3.45 |\n",
      "|       4 |              5 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "36.21\n",
      "72.41\n",
      "3.450000000000003\n",
      "3.450000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [3, 3, 10, 0, 4]\n",
      "After augmentation, size of train_set:  713  unlabeled set:  2619  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.639333993196487 0.9901823281907434 10.705179691314697 0.025 5.473099231719971 0.3931034482758621 82.76207756996155\n",
      "Gain in accuracy:  -2.7586206896551744\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           17.24 |\n",
      "|       2 |            100 |           81.03 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "17.239999999999995\n",
      "81.03\n",
      "0.0\n",
      "3.450000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [2, 0, 14, 2, 2]\n",
      "After augmentation, size of train_set:  733  unlabeled set:  2599  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.215319946408272 0.9918144611186903 11.329284906387329 0.05 5.549704432487488 0.3896551724137931 100.17501592636108\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           25.86 |\n",
      "|       2 |            100 |           70.69 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |             10 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "25.86\n",
      "70.69\n",
      "0.0\n",
      "3.450000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 6, 7, 0, 3]\n",
      "After augmentation, size of train_set:  753  unlabeled set:  2579  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.314150840044022 0.9933598937583001 10.72024154663086 0.025 5.283692836761475 0.41379310344827586 88.62260174751282\n",
      "Gain in accuracy:  2.4137931034482776\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           75.86 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              0 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "24.14\n",
      "75.86\n",
      "1.7199999999999989\n",
      "8.620000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [5, 1, 12, 1, 1]\n",
      "After augmentation, size of train_set:  773  unlabeled set:  2559  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.162940409034491 0.9935316946959897 11.436334371566772 0.0 5.567762613296509 0.39655172413793105 83.14290380477905\n",
      "Gain in accuracy:  -1.724137931034484\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           20.69 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |              0 |            3.45 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "20.689999999999998\n",
      "77.59\n",
      "0.0\n",
      "3.450000000000003\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [6, 3, 9, 0, 2]\n",
      "After augmentation, size of train_set:  793  unlabeled set:  2539  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.9185867980122566 0.9936948297604036 10.269769310951233 0.05 5.377768039703369 0.3758620689655172 90.39268326759338\n",
      "Gain in accuracy:  -2.068965517241381\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           89.66 |\n",
      "|       1 |            100 |           15.52 |\n",
      "|       2 |            100 |           77.59 |\n",
      "|       3 |              5 |            0    |\n",
      "|       4 |              5 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "89.66\n",
      "15.519999999999996\n",
      "77.59\n",
      "0.0\n",
      "5.170000000000002\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 1, 12, 1, 2]\n",
      "After augmentation, size of train_set:  813  unlabeled set:  2519  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.873022835701704 0.992619926199262 12.885380744934082 0.025 5.811085939407349 0.3896551724137931 115.19696927070618\n",
      "Gain in accuracy:  1.3793103448275872\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           94.83 |\n",
      "|       1 |            100 |           13.79 |\n",
      "|       2 |            100 |           81.03 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |              5 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "94.83\n",
      "13.790000000000006\n",
      "81.03\n",
      "0.0\n",
      "5.170000000000002\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [7, 7, 4, 1, 1]\n",
      "After augmentation, size of train_set:  833  unlabeled set:  2499  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.071123085916042 0.9939975990396158 11.219578266143799 0.025 5.293547987937927 0.4 110.47934770584106\n",
      "Gain in accuracy:  1.0344827586206904\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           93.1  |\n",
      "|       1 |            100 |           24.14 |\n",
      "|       2 |            100 |           74.14 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |              5 |            8.62 |\n",
      "Test accuracy is as follows - \n",
      "93.1\n",
      "24.14\n",
      "74.14\n",
      "0.0\n",
      "8.620000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "\n",
      " perClsSel -  [4, 4, 6, 3, 3]\n",
      "After augmentation, size of train_set:  853  unlabeled set:  2479  val set:  40\n",
      "\n",
      " Lake Set -  tensor([0, 0, 0,  ..., 4, 4, 4])\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.36496371589601 0.9929660023446659 12.374599695205688 0.025 5.639037132263184 0.39655172413793105 88.28046464920044\n",
      "Gain in accuracy:  -0.3448275862068968\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |            100 |           96.55 |\n",
      "|       1 |            100 |           15.52 |\n",
      "|       2 |            100 |           79.31 |\n",
      "|       3 |              5 |            1.72 |\n",
      "|       4 |              0 |            5.17 |\n",
      "Test accuracy is as follows - \n",
      "96.55\n",
      "15.519999999999996\n",
      "79.31\n",
      "1.7199999999999989\n",
      "5.170000000000002\n",
      "Total gain in accuracy:  1.3793103448275872\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"AL\",'badge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ecf8b9c"
   },
   "source": [
    "# References\n",
    "[1] Rishabh Iyer, Ninad Khargoankar, Jeff Bilmes, and Himanshu Asnani. Submodular combinatorialinformation measures with applications in machine learning.arXiv preprint arXiv:2006.15412,2020\n",
    "\n",
    "\n",
    "[2] Kaushal V, Kothawade S, Ramakrishnan G, Bilmes J, Iyer R. PRISM: A Unified Framework of Parameterized Submodular Information Measures for Targeted Data Subset Selection and Summarization. arXiv preprint arXiv:2103.00128. 2021 Feb 27.\n",
    "\n",
    "\n",
    "[3] Anupam Gupta and Roie Levin. The online submodular cover problem. InACM-SIAM Symposiumon Discrete Algorithms, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e93a22fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete all strategies is - 231.9071077893488 mins\n"
     ]
    }
   ],
   "source": [
    "end_time = time.monotonic()\n",
    "print('Time to complete all strategies is -', (end_time - start_time)/60, 'mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "trust_rare_classes_demo_dermamnist_targeted.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
