{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06904680",
   "metadata": {
    "id": "087af8f6"
   },
   "source": [
    "# Targeted Selection Demo For Biomedical Datasets With Rare Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a70d66",
   "metadata": {
    "id": "7a0fc69c"
   },
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c90815d",
   "metadata": {
    "id": "tOFuAsDz1a7b"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/decile-team/trust.git\n",
    "# !pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ submodlib\n",
    "# !git clone https://github.com/decile-team/distil.git\n",
    "# !pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2478e128",
   "metadata": {
    "id": "3b905244"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import copy\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from matplotlib import pyplot as plt\n",
    "from trust.trust.utils.models.resnet import ResNet18\n",
    "from trust.trust.utils.models.resnet import ResNet50\n",
    "from trust.trust.utils.custom_dataset_medmnist import load_biodataset_custom\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "from math import floor\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from trust.trust.strategies.smi import SMI\n",
    "from trust.trust.strategies.random_sampling import RandomSampling\n",
    "from distil.distil.active_learning_strategies.entropy_sampling import EntropySampling\n",
    "from distil.distil.active_learning_strategies.badge import BADGE\n",
    "\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "from trust.trust.utils.utils import *\n",
    "from trust.trust.utils.viz import tsne_smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb61f28",
   "metadata": {
    "id": "ec462346"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7922c3e1",
   "metadata": {
    "id": "5c36c6b4"
   },
   "outputs": [],
   "source": [
    "def model_eval_loss(data_loader, model, criterion):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "                \n",
    "def create_model(name, num_cls, device, embedding_type):\n",
    "    if name == 'ResNet18':\n",
    "        if embedding_type == \"gradients\":\n",
    "            model = ResNet18(num_cls)\n",
    "        else:\n",
    "            model = models.resnet18()\n",
    "    elif name == 'ResNet50':\n",
    "        if embedding_type == \"gradients\":\n",
    "            model = ResNet50(num_cls)\n",
    "        else:\n",
    "            model = models.resnet50()\n",
    "    elif name == 'MnistNet':\n",
    "        model = MnistNet()\n",
    "    elif name == 'ResNet164':\n",
    "        model = ResNet164(num_cls)\n",
    "    model.apply(init_weights)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def loss_function():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion_nored = nn.CrossEntropyLoss(reduction='none')\n",
    "    return criterion, criterion_nored\n",
    "\n",
    "def optimizer_with_scheduler(model, num_epochs, learning_rate, m=0.9, wd=5e-4):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                          momentum=m, weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def optimizer_without_scheduler(model, learning_rate, m=0.9, wd=5e-4):\n",
    "#     optimizer = optim.Adam(model.parameters(),weight_decay=wd)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                          momentum=m, weight_decay=wd)\n",
    "    return optimizer\n",
    "\n",
    "def generate_cumulative_timing(mod_timing):\n",
    "    tmp = 0\n",
    "    mod_cum_timing = np.zeros(len(mod_timing))\n",
    "    for i in range(len(mod_timing)):\n",
    "        tmp += mod_timing[i]\n",
    "        mod_cum_timing[i] = tmp\n",
    "    return mod_cum_timing/3600\n",
    "\n",
    "def displayTable(val_err_log, tst_err_log):\n",
    "    col1 = [str(i) for i in range(10)]\n",
    "    val_acc = [str(100-i) for i in val_err_log]\n",
    "    tst_acc = [str(100-i) for i in tst_err_log]\n",
    "    table = [col1, val_acc, tst_acc]\n",
    "    table = map(list, zip(*table))\n",
    "    print(tabulate(table, headers=['Class', 'Val Accuracy', 'Test Accuracy'], tablefmt='orgtbl'))\n",
    "    print('Test accuracy is as follows - ')\n",
    "    for i in tst_acc:\n",
    "        print(i)\n",
    "        \n",
    "\n",
    "def find_err_per_class(test_set, val_set, final_val_classifications, final_val_predictions, final_tst_classifications, \n",
    "                       final_tst_predictions, saveDir, prefix):\n",
    "    val_err_idx = list(np.where(np.array(final_val_classifications) == False)[0])\n",
    "    tst_err_idx = list(np.where(np.array(final_tst_classifications) == False)[0])\n",
    "    val_class_err_idxs = []\n",
    "    tst_err_log = []\n",
    "    val_err_log = []\n",
    "    for i in range(num_cls):\n",
    "        tst_class_idxs = list(torch.where(torch.Tensor(test_set.targets) == i)[0].cpu().numpy())\n",
    "        val_class_idxs = list(torch.where(torch.Tensor(val_set.targets.float()) == i)[0].cpu().numpy())\n",
    "        #err classifications per class\n",
    "        val_err_class_idx = set(val_err_idx).intersection(set(val_class_idxs))\n",
    "        tst_err_class_idx = set(tst_err_idx).intersection(set(tst_class_idxs))\n",
    "        if(len(val_class_idxs)>0):\n",
    "            val_error_perc = round((len(val_err_class_idx)/len(val_class_idxs))*100,2)\n",
    "        else:\n",
    "            val_error_perc = 0\n",
    "        tst_error_perc = round((len(tst_err_class_idx)/len(tst_class_idxs))*100,2)\n",
    "#         print(\"val, test error% for class \", i, \" : \", val_error_perc, tst_error_perc)\n",
    "        val_class_err_idxs.append(val_err_class_idx)\n",
    "        tst_err_log.append(tst_error_perc)\n",
    "        val_err_log.append(val_error_perc)\n",
    "    displayTable(val_err_log, tst_err_log)\n",
    "    tst_err_log.append(sum(tst_err_log)/len(tst_err_log))\n",
    "    val_err_log.append(sum(val_err_log)/len(val_err_log))\n",
    "    return tst_err_log, val_err_log, val_class_err_idxs\n",
    "\n",
    "\n",
    "def aug_train_subset(train_set, lake_set, true_lake_set, subset, lake_subset_idxs, budget, augrandom=False):\n",
    "    all_lake_idx = list(range(len(lake_set)))\n",
    "    if(not(len(subset)==budget) and augrandom):\n",
    "        print(\"Budget not filled, adding \", str(int(budget) - len(subset)), \" randomly.\")\n",
    "        remain_budget = int(budget) - len(subset)\n",
    "        remain_lake_idx = list(set(all_lake_idx) - set(subset))\n",
    "        random_subset_idx = list(np.random.choice(np.array(remain_lake_idx), size=int(remain_budget), replace=False))\n",
    "        subset += random_subset_idx\n",
    "    if str(type(true_lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        lake_ss = SubsetWithTargets(true_lake_set, subset, torch.Tensor(true_lake_set.targets.astype(np.float))[subset])\n",
    "    else:\n",
    "        lake_ss = SubsetWithTargets(true_lake_set, subset, torch.Tensor(true_lake_set.targets.float())[subset])\n",
    "    remain_lake_idx = list(set(all_lake_idx) - set(lake_subset_idxs))\n",
    "    if str(type(true_lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        remain_lake_set = SubsetWithTargets(lake_set, remain_lake_idx, torch.Tensor(lake_set.targets.astype(np.float))[remain_lake_idx])\n",
    "    else:\n",
    "        remain_lake_set = SubsetWithTargets(lake_set, remain_lake_idx, torch.Tensor(lake_set.targets.float())[remain_lake_idx])\n",
    "    if str(type(true_lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        remain_true_lake_set = SubsetWithTargets(true_lake_set, remain_lake_idx, torch.Tensor(true_lake_set.targets.astype(np.float))[remain_lake_idx])\n",
    "    else:\n",
    "        remain_true_lake_set = SubsetWithTargets(true_lake_set, remain_lake_idx, torch.Tensor(true_lake_set.targets.float())[remain_lake_idx])\n",
    "#     print(len(lake_ss),len(remain_lake_set),len(lake_set))\n",
    "    aug_train_set = torch.utils.data.ConcatDataset([train_set, lake_ss])\n",
    "    aug_trainloader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True, pin_memory=True)\n",
    "    return aug_train_set, remain_lake_set, remain_true_lake_set, lake_ss\n",
    "                        \n",
    "def getQuerySet(val_set, val_class_err_idxs, imb_cls_idx, miscls):\n",
    "    miscls_idx = []\n",
    "    if miscls == 'target':\n",
    "        # List of number denoting misclassified examples per class\n",
    "        print(\"\\n val_class_err_idxs - \", val_class_err_idxs)\n",
    "        len_val_class_error_idx = []\n",
    "        for i in val_class_err_idxs:\n",
    "            len_val_class_error_idx.append(len(i))\n",
    "\n",
    "        least_val_acc_class = len_val_class_error_idx.index(max(len_val_class_error_idx))\n",
    "\n",
    "        print('Class with most misclassified examples is - ', least_val_acc_class)\n",
    "        \n",
    "        for i in range(len(val_class_err_idxs)):\n",
    "            if i == least_val_acc_class:\n",
    "                miscls_idx += list(val_class_err_idxs[least_val_acc_class])\n",
    "        else:\n",
    "            val_class_err_idxs[i] = set()\n",
    "        \n",
    "        print(miscls_idx)        \n",
    "\n",
    "    elif(miscls):\n",
    "        for i in range(len(val_class_err_idxs)):\n",
    "            if i in imb_cls_idx:\n",
    "                miscls_idx += val_class_err_idxs[i]\n",
    "        print(\"Total misclassified examples from imbalanced classes (Size of query set): \", len(miscls_idx))\n",
    "    else:\n",
    "        for i in imb_cls_idx:\n",
    "            imb_cls_samples = list(torch.where(torch.Tensor(val_set.targets.float()) == i)[0].cpu().numpy())\n",
    "            miscls_idx += imb_cls_samples\n",
    "        print(\"Total samples from imbalanced classes as targets (Size of query set): \", len(miscls_idx))\n",
    "    \n",
    "    return Subset(val_set, miscls_idx), val_set.targets[miscls_idx]\n",
    "\n",
    "def getPerClassSel(lake_set, subset, num_cls):\n",
    "    perClsSel = []\n",
    "    if str(type(lake_set.targets)) == \"<class 'numpy.ndarray'>\":\n",
    "        subset_cls = torch.Tensor(lake_set.targets.astype(np.float))[subset]\n",
    "    else:\n",
    "        subset_cls = torch.Tensor(lake_set.targets.float())[subset]\n",
    "    for i in range(num_cls):\n",
    "        cls_subset_idx = list(torch.where(subset_cls == i)[0].cpu().numpy())\n",
    "        perClsSel.append(len(cls_subset_idx))\n",
    "    return perClsSel\n",
    "\n",
    "def print_final_results(res_dict, sel_cls_idx):\n",
    "    print(\"Gain in overall test accuracy: \", res_dict['test_acc'][1]-res_dict['test_acc'][0])\n",
    "    bf_sel_cls_acc = np.array(res_dict['all_class_acc'][0])[sel_cls_idx]\n",
    "    af_sel_cls_acc = np.array(res_dict['all_class_acc'][1])[sel_cls_idx]\n",
    "    print(\"Gain in targeted test accuracy: \", np.mean(af_sel_cls_acc-bf_sel_cls_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96332b0d",
   "metadata": {
    "id": "9d02859f"
   },
   "source": [
    "# Data, Model & Experimental Settings\n",
    "The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. The training set contains 50,000 images and test set contains 10,000 images. We will use custom_dataset() function in Trust to simulated a class imbalance scenario using the split_cfg dictionary given below. We then use a ResNet18 model as our task DNN and train it on the simulated imbalanced version of the CIFAR-10 dataset. Next we perform targeted selection using various SMI functions and compare their gain in overall accuracy as well as on the imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93b2ff0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96ce679b",
    "outputId": "e21e7138-ca97-469b-ae96-a44ebc3f3a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_cfg: {'num_cls_imbalance': 7, 'sel_cls_idx': [0, 1, 2, 3, 4, 5, 6], 'per_imbclass_train': {0: 57, 1: 95, 2: 212, 3: 15, 4: 215, 5: 1333, 6: 20}, 'per_imbclass_val': {0: 10, 1: 0, 2: 0, 3: 10, 4: 0, 5: 0, 6: 10}, 'per_imbclass_lake': {0: 222, 1: 381, 2: 849, 3: 52, 4: 860, 5: 5334, 6: 74}, 'per_imbclass_test': {0: 38, 1: 38, 2: 38, 3: 38, 4: 38, 5: 38, 6: 38}}\n"
     ]
    }
   ],
   "source": [
    "feature = \"longtail\"\n",
    "device_id = 2\n",
    "run=\"exp_5_1\"\n",
    "datadir = 'isic_data/'\n",
    "data_name = 'isic_2018'\n",
    "model_name = 'ResNet18'\n",
    "learning_rate = 0.0003\n",
    "computeClassErrorLog = True\n",
    "device = \"cuda:\"+str(device_id) if torch.cuda.is_available() else \"cpu\"\n",
    "#Set miscls to 'target' to target only class with most misclassified examples\n",
    "#Set to True if only the misclassified examples from the imbalanced classes is to be used\n",
    "miscls = 'target'\n",
    "embedding_type = \"gradients\" #Type of the representation to use (gradients/features)\n",
    "num_cls = 7\n",
    "budget = 20\n",
    "visualize_tsne = False\n",
    "tns = [] #train_num_samples\n",
    "imbf = 60 #imbalance factor\n",
    "import math\n",
    "for i in range(1,num_cls+1):\n",
    "    tns.append(math.ceil(5*(1.4**i)))\n",
    "# split_cfg = {\"num_cls_imbalance\":1,\n",
    "#              \"sel_cls_idx\":[0,1,2,3,4,5,6,7,8],\n",
    "#              \"per_imbclass_train\":{0:tns[0],1:tns[1],2:tns[2],3:tns[3],4:tns[4],5:tns[5],6:tns[6],7:tns[7],8:tns[8]},\n",
    "#              \"per_imbclass_val\":{0:10,1:10,2:10,3:10,4:10,5:10,6:10,7:10,8:10},\n",
    "#              \"per_imbclass_lake\":{0:tns[0]*imbf,1:tns[1]*imbf,2:tns[2]*imbf,3:tns[3]*imbf,4:tns[4]*imbf,5:tns[5]*imbf,6:tns[6]*imbf,7:tns[7]*imbf,8:tns[8]*imbf},\n",
    "#             } #cifar10\n",
    "split_cfg = {\"num_cls_imbalance\":7, # This is not used for longtail\n",
    "             \"sel_cls_idx\":[0,1,2,3,4,5,6],\n",
    "             # Number of images available combined for train + lake + val are as follows\n",
    "             #  0       1       2       3       4       5       6\n",
    "             #  289     476     1061    77      1075    666    104\n",
    "             \"per_imbclass_train\":{0:57,1:95,2:212,3:15,4:215,5:1333,6:20},\n",
    "             \"per_imbclass_val\":{0:10,1:0,2:0,3:10,4:0,5:0,6:10}, \n",
    "             \"per_imbclass_lake\":{0:222,1:381,2:849,3:52,4:860,5:5334,6:74},\n",
    "             \"per_imbclass_test\":{0:38,1:38,2:38,3:38,4:38,5:38,6:38}}\n",
    "print(\"split_cfg:\",split_cfg)\n",
    "initModelPath = \"./\"+data_name + \"_\" + model_name + \"_\" + str(learning_rate) + \"_\" + str(split_cfg[\"num_cls_imbalance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90596d35",
   "metadata": {
    "id": "d6d2a173"
   },
   "source": [
    "# Targeted Selection Algorithm\n",
    "1. Given: Initial Labeled set of Examples: ùê∏, large unlabeled dataset: ùëà, A target subset/slice where we want to improve accuracy: ùëá, Loss function ùêø for learning\n",
    "2. Train model with loss $\\mathcal L$ on labeled set $E$ and obtain parameters $\\theta_E$\n",
    "3. Compute the gradients $\\{\\nabla_{\\theta_E} \\mathcal L(x_i, y_i), i \\in U\\}$ (using hypothesized labels) and $\\{\\nabla_{\\theta_E} \\mathcal L(x_i, y_i), i \\in T\\}$. \n",
    "(This notebook uses gradients for representation. However, any other representation can be used. Trust also supports using features via the API.)\n",
    "4. Compute the similarity kernels $S$ (this includes kernel of the elements within $U$, within $T$ and between $U$ and $T$) and define a submodular function $f$ and diversity function $g$\n",
    "5. Compute subset $\\hat{A}$ by mazximizing the SMI function: $\\hat{A} \\gets \\max_{A \\subseteq U, |A|\\leq k} I_f(A;T) + \\gamma g(A)$\n",
    "6. Obtain the labels of the elements in $A^*$: $L(\\hat{A})$\n",
    "7. Train a model on the combined labeled set $E \\cup L(\\hat{A})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eec957a",
   "metadata": {
    "id": "91b510c9"
   },
   "outputs": [],
   "source": [
    "def run_targeted_selection(dataset_name, datadir, feature, model_name, budget, split_cfg, learning_rate, run,\n",
    "                device, computeErrorLog, strategy=\"SIM\", sf=\"\"):\n",
    "\n",
    "    #load the dataset in the class imbalance setting\n",
    "    train_set, val_set, test_set, lake_set, sel_cls_idx, num_cls = load_biodataset_custom(datadir, dataset_name, feature, split_cfg, False, False)\n",
    "    print(\"Indices of randomly selected classes for imbalance: \", sel_cls_idx)\n",
    "    \n",
    "    #Set batch size for train, validation and test datasets\n",
    "    N = len(train_set)\n",
    "    trn_batch_size = 20\n",
    "    val_batch_size = 10\n",
    "    tst_batch_size = 100\n",
    "\n",
    "    #Create dataloaders\n",
    "    trainloader = torch.utils.data.DataLoader(train_set, batch_size=trn_batch_size,\n",
    "                                              shuffle=True, pin_memory=True)\n",
    "\n",
    "    valloader = torch.utils.data.DataLoader(val_set, batch_size=val_batch_size, \n",
    "                                            shuffle=False, pin_memory=True)\n",
    "\n",
    "    tstloader = torch.utils.data.DataLoader(test_set, batch_size=tst_batch_size,\n",
    "                                             shuffle=False, pin_memory=True)\n",
    "    \n",
    "    lakeloader = torch.utils.data.DataLoader(lake_set, batch_size=tst_batch_size,\n",
    "                                         shuffle=False, pin_memory=True)\n",
    "    true_lake_set = copy.deepcopy(lake_set)\n",
    "    # Budget for subset selection\n",
    "    bud = budget\n",
    "   \n",
    "    # Variables to store accuracies\n",
    "    num_rounds=10 #The first round is for training the initial model and the second round is to train the final model\n",
    "    fulltrn_losses = np.zeros(num_rounds)\n",
    "    val_losses = np.zeros(num_rounds)\n",
    "    tst_losses = np.zeros(num_rounds)\n",
    "    timing = np.zeros(num_rounds)\n",
    "    val_acc = np.zeros(num_rounds)\n",
    "    full_trn_acc = np.zeros(num_rounds)\n",
    "    tst_acc = np.zeros(num_rounds)\n",
    "    final_tst_predictions = []\n",
    "    final_tst_classifications = []\n",
    "    best_val_acc = -1\n",
    "    csvlog = []\n",
    "    val_csvlog = []\n",
    "    # Results logging file\n",
    "    all_logs_dir = './results/' + dataset_name  + '/' + feature + '/'+  sf + '/' + str(bud) + '/' + str(run)\n",
    "    print(\"Saving results to: \", all_logs_dir)\n",
    "    subprocess.run([\"mkdir\", \"-p\", all_logs_dir]) #Uncomment for saving results\n",
    "    exp_name = dataset_name + \"_\" + feature +  \"_\" + strategy + \"_\" + str(len(sel_cls_idx))  +\"_\" + sf +  '_budget:' + str(bud) + '_rounds:' + str(num_rounds) + '_runs' + str(run)\n",
    "\n",
    "    #Create a dictionary for storing results and the experimental setting\n",
    "    res_dict = {\"dataset\":data_name, \n",
    "                \"feature\":feature, \n",
    "                \"sel_func\":sf,\n",
    "                \"sel_budget\":budget, \n",
    "                \"num_selections\":num_rounds-1, \n",
    "                \"model\":model_name, \n",
    "                \"learning_rate\":learning_rate, \n",
    "                \"setting\":split_cfg, \n",
    "                \"all_class_acc\":None, \n",
    "                \"test_acc\":[],\n",
    "                \"sel_per_cls\":[], \n",
    "                \"sel_cls_idx\":sel_cls_idx}\n",
    "    \n",
    "    # Model Creation\n",
    "    model = create_model(model_name, num_cls, device, embedding_type)\n",
    "    model1 = create_model(model_name, num_cls, device, embedding_type)\n",
    "    strategy_args = {'batch_size': 20, 'device':device, 'embedding_type':'gradients', 'keep_embedding':True}\n",
    "    unlabeled_lake_set = LabeledToUnlabeledDataset(lake_set)\n",
    "    \n",
    "    if(strategy == \"AL\"):\n",
    "        if(sf==\"badge\"):\n",
    "            strategy_sel = BADGE(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"us\"):\n",
    "            strategy_sel = EntropySampling(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"glister\" or sf==\"glister-tss\"):\n",
    "            strategy_sel = GLISTER(train_set, unlabeled_lake_set, model, num_cls, strategy_args, val_set, typeOf='rand', lam=0.1)\n",
    "        elif(sf==\"gradmatch-tss\"):\n",
    "            strategy_sel = GradMatchActive(train_set, unlabeled_lake_set, model, num_cls, strategy_args, val_set)\n",
    "        elif(sf==\"coreset\"):\n",
    "            strategy_sel = CoreSet(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"leastconf\"):\n",
    "            strategy_sel = LeastConfidence(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        elif(sf==\"margin\"):\n",
    "            strategy_sel = MarginSampling(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "    if(strategy == \"SIM\"):\n",
    "        strategy_args['smi_function'] = sf\n",
    "        strategy_sel = SMI(train_set, unlabeled_lake_set, val_set, model, num_cls, strategy_args)\n",
    "    if(strategy == \"random\"):\n",
    "        strategy_sel = RandomSampling(train_set, unlabeled_lake_set, model, num_cls, strategy_args)\n",
    "        \n",
    "    # Loss Functions\n",
    "    criterion, criterion_nored = loss_function()\n",
    "\n",
    "    # Getting the optimizer and scheduler\n",
    "    optimizer = optimizer_without_scheduler(model, learning_rate)\n",
    "\n",
    "    for i in range(num_rounds):\n",
    "        tst_loss = 0\n",
    "        tst_correct = 0\n",
    "        tst_total = 0\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        if(i==0):\n",
    "            print(\"Initial training epoch\")\n",
    "            if(os.path.exists(initModelPath)): #Read the initial trained model if it exists\n",
    "                model.load_state_dict(torch.load(initModelPath, map_location=device))\n",
    "                print(\"Init model loaded from disk, skipping init training: \", initModelPath)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    final_val_predictions = []\n",
    "                    final_val_classifications = []\n",
    "                    for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "                        inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        val_loss += loss.item()\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        val_total += targets.size(0)\n",
    "                        val_correct += predicted.eq(targets).sum().item()\n",
    "                        final_val_predictions += list(predicted.cpu().numpy())\n",
    "                        final_val_classifications += list(predicted.eq(targets).cpu().numpy())\n",
    "  \n",
    "                    final_tst_predictions = []\n",
    "                    final_tst_classifications = []\n",
    "                    for batch_idx, (inputs, targets) in enumerate(tstloader):\n",
    "                        inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        tst_loss += loss.item()\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        tst_total += targets.size(0)\n",
    "                        tst_correct += predicted.eq(targets).sum().item()\n",
    "                        final_tst_predictions += list(predicted.cpu().numpy())\n",
    "                        final_tst_classifications += list(predicted.eq(targets).cpu().numpy())                \n",
    "                    best_val_acc = (val_correct/val_total)\n",
    "                    val_acc[i] = val_correct / val_total\n",
    "                    tst_acc[i] = tst_correct / tst_total\n",
    "                    val_losses[i] = val_loss\n",
    "                    tst_losses[i] = tst_loss\n",
    "                    res_dict[\"test_acc\"].append(tst_acc[i]*100)\n",
    "                continue\n",
    "        else:\n",
    "            #Remove true labels from the unlabeled dataset, the hypothesized labels are computed when select is called\n",
    "            unlabeled_lake_set = LabeledToUnlabeledDataset(lake_set)\n",
    "            strategy_sel.update_data(train_set, unlabeled_lake_set)\n",
    "            #compute the error log before every selection\n",
    "            if(computeErrorLog):\n",
    "                tst_err_log, val_err_log, val_class_err_idxs = find_err_per_class(test_set, val_set, final_val_classifications, final_val_predictions, final_tst_classifications, final_tst_predictions, all_logs_dir, sf+\"_\"+str(bud))\n",
    "                csvlog.append([100-x for x in tst_err_log])\n",
    "                val_csvlog.append([100-x for x in val_err_log])\n",
    "            ####SIM####\n",
    "            if(strategy==\"SIM\" or strategy==\"SF\"):\n",
    "                if(sf.endswith(\"mi\")):\n",
    "                    if(feature==\"classimb\" or feature=='longtail'):\n",
    "                        #make a dataloader for the misclassifications - only for experiments with targets\n",
    "                        miscls_set, miscls_set_targets = getQuerySet(val_set, val_class_err_idxs, sel_cls_idx, miscls)\n",
    "                        strategy_sel.update_queries(miscls_set)\n",
    "            elif(strategy==\"AL\"):\n",
    "                if(sf==\"glister-tss\" or sf==\"gradmatch-tss\"):\n",
    "                    miscls_set = getQuerySet(val_set, val_class_err_idxs, sel_cls_idx, miscls)\n",
    "                    strategy_sel.update_queries(miscls_set)\n",
    "                    print(\"reinit AL with targeted miscls samples\")\n",
    "            \n",
    "            strategy_sel.update_model(model)\n",
    "            subset = strategy_sel.select(budget)\n",
    "            print(\"#### Selection Complete, Now re-training with augmented subset ####\")\n",
    "            if(visualize_tsne):\n",
    "                tsne_plt = tsne_smi(strategy_sel.unlabeled_data_embedding.cpu(),\n",
    "                                    lake_set.targets,\n",
    "                                    strategy_sel.query_embedding.cpu(),\n",
    "                                    miscls_set_targets,\n",
    "                                    subset)\n",
    "                print(\"Computed TSNE plot of the selection\")\n",
    "            lake_subset_idxs = subset #indices wrt to lake that need to be removed from the lake\n",
    "            perClsSel = getPerClassSel(true_lake_set, lake_subset_idxs, num_cls)\n",
    "            res_dict['sel_per_cls'].append(perClsSel)\n",
    "            \n",
    "            #augment the train_set with selected indices from the lake\n",
    "            train_set, lake_set, true_lake_set, add_val_set = aug_train_subset(train_set, lake_set, true_lake_set, subset, lake_subset_idxs, budget, True) #aug train with random if budget is not filled\n",
    "            print(\"After augmentation, size of train_set: \", len(train_set), \" unlabeled set: \", len(lake_set), \" val set: \", len(val_set))\n",
    "    \n",
    "#           Reinit train and lake loaders with new splits and reinit the model\n",
    "            trainloader = torch.utils.data.DataLoader(train_set, batch_size=trn_batch_size, shuffle=True, pin_memory=True)\n",
    "            lakeloader = torch.utils.data.DataLoader(lake_set, batch_size=tst_batch_size, shuffle=False, pin_memory=True)\n",
    "            model = create_model(model_name, num_cls, device, strategy_args['embedding_type'])\n",
    "            optimizer = optimizer_without_scheduler(model, learning_rate)\n",
    "                \n",
    "        #Start training\n",
    "        start_time = time.time()\n",
    "        num_ep=1\n",
    "#         while(num_ep<150):\n",
    "        while(full_trn_acc[i]<0.99 and num_ep<100):\n",
    "            model.train()\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                # Variables in Pytorch are differentiable.\n",
    "                inputs, target = Variable(inputs), Variable(inputs)\n",
    "                # This will zero out the gradients for this batch.\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "#             scheduler.step()\n",
    "          \n",
    "            full_trn_loss = 0\n",
    "            full_trn_correct = 0\n",
    "            full_trn_total = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(trainloader): #Compute Train accuracy\n",
    "                    inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    full_trn_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    full_trn_total += targets.size(0)\n",
    "                    full_trn_correct += predicted.eq(targets).sum().item()\n",
    "                full_trn_acc[i] = full_trn_correct / full_trn_total\n",
    "                print(\"Selection Epoch \", i, \" Training epoch [\" , num_ep, \"]\" , \" Training Acc: \", full_trn_acc[i], end=\"\\r\")\n",
    "                num_ep+=1\n",
    "            timing[i] = time.time() - start_time\n",
    "        with torch.no_grad():\n",
    "            final_val_predictions = []\n",
    "            final_val_classifications = []\n",
    "            for batch_idx, (inputs, targets) in enumerate(valloader): #Compute Val accuracy\n",
    "                inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "                final_val_predictions += list(predicted.cpu().numpy())\n",
    "                final_val_classifications += list(predicted.eq(targets).cpu().numpy())\n",
    "\n",
    "            final_tst_predictions = []\n",
    "            final_tst_classifications = []\n",
    "            for batch_idx, (inputs, targets) in enumerate(tstloader): #Compute test accuracy\n",
    "                inputs, targets = inputs.to(device), targets.to(device, non_blocking=True)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                tst_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                tst_total += targets.size(0)\n",
    "                tst_correct += predicted.eq(targets).sum().item()\n",
    "                final_tst_predictions += list(predicted.cpu().numpy())\n",
    "                final_tst_classifications += list(predicted.eq(targets).cpu().numpy())                \n",
    "            val_acc[i] = val_correct / val_total\n",
    "            tst_acc[i] = tst_correct / tst_total\n",
    "            val_losses[i] = val_loss\n",
    "            fulltrn_losses[i] = full_trn_loss\n",
    "            tst_losses[i] = tst_loss\n",
    "            full_val_acc = list(np.array(val_acc))\n",
    "            full_timing = list(np.array(timing))\n",
    "            res_dict[\"test_acc\"].append(tst_acc[i]*100)\n",
    "            print('Epoch:', i + 1, 'FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time:', full_trn_loss, full_trn_acc[i], val_loss, val_acc[i], tst_loss, tst_acc[i], timing[i])\n",
    "            print(\"Gain in accuracy: \",res_dict['test_acc'][i]-res_dict['test_acc'][i-1])\n",
    "        if(i==0): \n",
    "            print(\"Saving initial model\") \n",
    "            torch.save(model.state_dict(), initModelPath) #save initial train model if not present\n",
    "            \n",
    "    #Compute the statistics of the final model\n",
    "    if(computeErrorLog):\n",
    "        print(\"**** Final Metrics after Targeted Learning ****\")\n",
    "        tst_err_log, val_err_log, val_class_err_idxs = find_err_per_class(test_set, val_set, final_val_classifications, final_val_predictions, final_tst_classifications, final_tst_predictions, all_logs_dir, sf+\"_\"+str(bud))\n",
    "        csvlog.append([100-x for x in tst_err_log])\n",
    "        val_csvlog.append([100-x for x in val_err_log])\n",
    "        res_dict[\"all_class_acc\"] = csvlog\n",
    "        res_dict[\"all_val_class_acc\"] = val_csvlog\n",
    "        \n",
    "    #Print overall acc improvement and rare class acc improvement, show that TL selected relevant points in space, is possible show some images\n",
    "#     print_final_results(res_dict, sel_cls_idx)\n",
    "    print(\"Total gain in accuracy: \",res_dict['test_acc'][i]-res_dict['test_acc'][0])\n",
    "    \n",
    "    #save results dir with test acc and per class selections\n",
    "    with open(os.path.join(all_logs_dir, exp_name+\".json\"), 'w') as fp:\n",
    "        json.dump(res_dict, fp)\n",
    "    \n",
    "#     tsne_plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d918f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.monotonic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74434be",
   "metadata": {
    "id": "3240bc93"
   },
   "source": [
    "# Submodular Mutual Information (SMI)\n",
    "\n",
    "We let $V$ denote the ground-set of $n$ data points $V = \\{1, 2, 3,...,n \\}$ and a set function $f:\n",
    " 2^{V} \\xrightarrow{} \\Re$. Given a set of items $A, B \\subseteq V$, the submodular mutual information (MI)[1,3] is defined as $I_f(A; B) = f(A) + f(B) - f(A \\cup B)$. Intuitively, this measures the similarity between $B$ and $A$ and we refer to $B$ as the query set.\n",
    "\n",
    "In [2], they extend MI to handle the case when the target can come from an auxiliary set $V^{\\prime}$ different from the ground set $V$. For targeted data subset selection, $V$ is the source set of data instances and the target is a subset of data points (validation set or the specific set of examples of interest).\n",
    "Let $\\Omega  = V \\cup V^{\\prime}$. We define a set function $f: 2^{\\Omega} \\rightarrow \\Re$. Although $f$ is defined on $\\Omega$, the discrete optimization problem will only be defined on subsets $A \\subseteq V$. To find an optimal subset given a query set $Q \\subseteq V^{\\prime}$, we can define $g_{Q}(A) = I_f(A; Q)$, $A \\subseteq V$ and maximize the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542874e4",
   "metadata": {
    "id": "5c3045e5"
   },
   "source": [
    "# FL1MI\n",
    "\n",
    "In the first variant of FL, we set the unlabeled dataset to be $V$. The SMI instantiation of FL1MI can be defined as:\n",
    "\\begin{align}\n",
    "I_f(A;Q)=\\sum_{i \\in V}\\min(\\max_{j \\in A}s_{ij}, \\eta \\max_{j \\in Q}sq_{ij})\n",
    "\\end{align}\n",
    "\n",
    "The first term in the min(.) of FL1MI models diversity, and the second term models query relevance. An increase in the value of $\\eta$ causes the resulting summary to become more relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2feabba4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a96a686",
    "outputId": "726a587e-79f9-42a7-8910-f86b718eb651",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/fl1mi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Epoch: 1 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 9.8949217479676 0.9912686183872624 9.24486517906189 0.06666666666666667 6.603210687637329 0.3383458646616541 129.48101711273193\n",
      "Gain in accuracy:  0.0\n",
      "Saving initial model\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.581688461825252 0.9949161159125572 8.575273990631104 0.23333333333333334 6.646966338157654 0.37218045112781956 163.15098309516907\n",
      "Gain in accuracy:  3.383458646616546\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           15.79 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             60 |           28.95 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "36.84\n",
      "68.42\n",
      "0.0\n",
      "26.319999999999993\n",
      "84.21000000000001\n",
      "28.950000000000003\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 27, 29, 22}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.873271803371608 0.9924509310518369 7.633904218673706 0.23333333333333334 5.768601298332214 0.3533834586466165 129.96298146247864\n",
      "Gain in accuracy:  -1.8796992481203034\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |            7.89 |\n",
      "|       1 |            100 |           50    |\n",
      "|       2 |            100 |           52.63 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           21.05 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             60 |           26.32 |\n",
      "Test accuracy is as follows - \n",
      "7.890000000000001\n",
      "50.0\n",
      "52.63\n",
      "0.0\n",
      "21.049999999999997\n",
      "89.47\n",
      "26.319999999999993\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 27, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.63380666449666 0.9945191828599901 5.9010169506073 0.3333333333333333 5.764484524726868 0.37218045112781956 142.57198977470398\n",
      "Gain in accuracy:  1.8796992481203034\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             40 |           21.05 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           52.63 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           15.79 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             60 |           44.74 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "36.84\n",
      "52.63\n",
      "0.0\n",
      "15.790000000000006\n",
      "89.47\n",
      "44.74\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {24, 25, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.496569267474115 0.9901332017760237 6.3020042181015015 0.26666666666666666 5.4413299560546875 0.39849624060150374 153.38512659072876\n",
      "Gain in accuracy:  2.6315789473684177\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           21.05 |\n",
      "|       1 |            100 |           52.63 |\n",
      "|       2 |            100 |           44.74 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           21.05 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             70 |           55.26 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "52.63\n",
      "44.74\n",
      "0.0\n",
      "21.049999999999997\n",
      "84.21000000000001\n",
      "55.26\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.298032247461379 0.9956033219345384 7.882345199584961 0.23333333333333334 5.786451101303101 0.41729323308270677 153.35924124717712\n",
      "Gain in accuracy:  1.8796992481203034\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           21.05 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           71.05 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           34.21 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             60 |           47.37 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "34.209999999999994\n",
      "71.05\n",
      "0.0\n",
      "34.209999999999994\n",
      "84.21000000000001\n",
      "47.37\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 27, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.226554336026311 0.99225931301403 6.3468650579452515 0.3 5.4193936586380005 0.4323308270676692 148.14235734939575\n",
      "Gain in accuracy:  1.5037593984962356\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           31.58 |\n",
      "|       1 |            100 |           44.74 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           73.68 |\n",
      "|       6 |             60 |           57.89 |\n",
      "Test accuracy is as follows - \n",
      "31.58\n",
      "44.74\n",
      "68.42\n",
      "0.0\n",
      "26.319999999999993\n",
      "73.68\n",
      "57.89\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 5, 6, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 27, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.824623020365834 0.9918543363679924 6.271849632263184 0.23333333333333334 5.253472030162811 0.40977443609022557 136.43434810638428\n",
      "Gain in accuracy:  -2.255639097744357\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           15.79 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             70 |           57.89 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "39.47\n",
      "63.16\n",
      "0.0\n",
      "23.680000000000007\n",
      "86.84\n",
      "57.89\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 21}]\n",
      "Class with most misclassified examples is -  0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.946745105087757 0.9914570479354533 7.279668927192688 0.3 5.3728203773498535 0.44360902255639095 151.14162063598633\n",
      "Gain in accuracy:  3.383458646616539\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           23.68 |\n",
      "|       1 |            100 |           47.37 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           34.21 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             60 |           57.89 |\n",
      "Test accuracy is as follows - \n",
      "23.680000000000007\n",
      "47.37\n",
      "55.26\n",
      "0.0\n",
      "34.209999999999994\n",
      "92.11\n",
      "57.89\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 5, 6, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 27, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.9973253309726715 0.9915373765867419 6.898255348205566 0.3 6.019149541854858 0.39097744360902253 143.3241958618164\n",
      "Gain in accuracy:  -5.2631578947368425\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           18.42 |\n",
      "|       1 |            100 |           28.95 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           21.05 |\n",
      "|       5 |            100 |           94.74 |\n",
      "|       6 |             70 |           50    |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "28.950000000000003\n",
      "60.53\n",
      "0.0\n",
      "21.049999999999997\n",
      "94.74\n",
      "50.0\n",
      "Total gain in accuracy:  5.2631578947368425\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"SIM\",'fl1mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4ae69",
   "metadata": {
    "id": "8b1fc84e"
   },
   "source": [
    "# FL2MI\n",
    "\n",
    "In the V2 variant, we set $D$ to be $V \\cup Q$. The SMI instantiation of FL2MI can be defined as:\n",
    "\\begin{align} \\label{eq:FL2MI}\n",
    "I_f(A;Q)=\\sum_{i \\in Q} \\max_{j \\in A} sq_{ij} + \\eta\\sum_{i \\in A} \\max_{j \\in Q} sq_{ij}\n",
    "\\end{align}\n",
    "FL2MI is very intuitive for query relevance as well. It measures the representation of data points that are the most relevant to the query set and vice versa. It can also be thought of as a bidirectional representation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a360d9a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1e29177",
    "outputId": "7db4433a-368a-46d0-ea95-932be07ecd46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/fl2mi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./isic_2018_ResNet18_0.0003_7\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.49391989223659 0.9918657854600915 9.848490238189697 0.16666666666666666 6.873440146446228 0.33458646616541354 159.9255633354187\n",
      "Gain in accuracy:  -0.3759398496240607\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |            7.89 |\n",
      "|       1 |            100 |           50    |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             30 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "7.890000000000001\n",
      "50.0\n",
      "60.53\n",
      "0.0\n",
      "23.680000000000007\n",
      "86.84\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.046477416530252 0.9919476597886261 8.401160717010498 0.13333333333333333 6.538386106491089 0.32706766917293234 125.18954563140869\n",
      "Gain in accuracy:  -0.7518796992481143\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           18.42 |\n",
      "|       1 |            100 |           28.95 |\n",
      "|       2 |            100 |           65.79 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           34.21 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             20 |            0    |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "28.950000000000003\n",
      "65.78999999999999\n",
      "0.0\n",
      "34.209999999999994\n",
      "81.58\n",
      "0.0\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 23, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.586075108498335 0.9915296462381664 7.8194780349731445 0.2 6.224035739898682 0.34962406015037595 124.7725441455841\n",
      "Gain in accuracy:  2.255639097744357\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             40 |           23.68 |\n",
      "|       1 |            100 |           50    |\n",
      "|       2 |            100 |           52.63 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             20 |           10.53 |\n",
      "Test accuracy is as follows - \n",
      "23.680000000000007\n",
      "50.0\n",
      "52.63\n",
      "0.0\n",
      "23.680000000000007\n",
      "84.21000000000001\n",
      "10.530000000000001\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 23, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.85192141868174 0.9901332017760237 8.789972305297852 0.1 6.698000192642212 0.3157894736842105 115.04931116104126\n",
      "Gain in accuracy:  -3.3834586466165426\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           18.42 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           50    |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           18.42 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |              0 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "42.11\n",
      "50.0\n",
      "0.0\n",
      "18.42\n",
      "89.47\n",
      "2.6299999999999955\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 5, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 9.421436127275229 0.9907181240840254 8.654417753219604 0.06666666666666667 6.172731637954712 0.32706766917293234 118.11384391784668\n",
      "Gain in accuracy:  1.1278195488721856\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           15.79 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           73.68 |\n",
      "|       6 |             20 |           13.16 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "39.47\n",
      "55.26\n",
      "0.0\n",
      "31.58\n",
      "73.68\n",
      "13.159999999999997\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.973205324262381 0.9966134494436382 8.191700458526611 0.1 6.795065402984619 0.34210526315789475 137.88843536376953\n",
      "Gain in accuracy:  1.5037593984962356\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           18.42 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           57.89 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             30 |            7.89 |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "39.47\n",
      "57.89\n",
      "0.0\n",
      "23.680000000000007\n",
      "92.11\n",
      "7.890000000000001\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.183510320261121 0.9937709631049353 6.8611568212509155 0.2 6.4682252407073975 0.34962406015037595 136.62177348136902\n",
      "Gain in accuracy:  0.7518796992481214\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             40 |           26.32 |\n",
      "|       1 |            100 |           26.32 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             20 |           23.68 |\n",
      "Test accuracy is as follows - \n",
      "26.319999999999993\n",
      "26.319999999999993\n",
      "60.53\n",
      "0.0\n",
      "23.680000000000007\n",
      "84.21000000000001\n",
      "23.680000000000007\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 5, 6, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.03486249037087 0.9957285239677266 7.635351657867432 0.16666666666666666 6.18289053440094 0.39473684210526316 129.53702926635742\n",
      "Gain in accuracy:  4.511278195488721\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           31.58 |\n",
      "|       1 |            100 |           57.89 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             20 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "31.58\n",
      "57.89\n",
      "68.42\n",
      "0.0\n",
      "26.319999999999993\n",
      "86.84\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.753917002119124 0.998589562764457 8.712109327316284 0.03333333333333333 6.649967551231384 0.3233082706766917 154.6644880771637\n",
      "Gain in accuracy:  -7.142857142857146\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           21.05 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            2.63 |\n",
      "|       4 |            100 |           15.79 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |              0 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "34.209999999999994\n",
      "60.53\n",
      "2.6299999999999955\n",
      "15.790000000000006\n",
      "89.47\n",
      "2.6299999999999955\n",
      "Total gain in accuracy:  -1.5037593984962427\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog, \n",
    "               \"SIM\",'fl2mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccf4fc",
   "metadata": {
    "id": "330ea94d"
   },
   "source": [
    "# GCMI\n",
    "\n",
    "The SMI instantiation of graph-cut (GCMI) is defined as:\n",
    "\\begin{align}\n",
    "I_f(A;Q)=2\\sum_{i \\in A} \\sum_{j \\in Q} sq_{ij}\n",
    "\\end{align}\n",
    "Since maximizing GCMI maximizes the joint pairwise sum with the query set, it will lead to a subset similar to the query set $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2585dde4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dc6e91d",
    "outputId": "a5140e1d-1c48-4882-a595-ee71c04d17e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/gcmi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./isic_2018_ResNet18_0.0003_7\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.598014615476131 0.9959328927300457 9.109812259674072 0.1 6.768056273460388 0.31203007518796994 125.32140493392944\n",
      "Gain in accuracy:  -2.6315789473684177\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           13.16 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             10 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "13.159999999999997\n",
      "36.84\n",
      "55.26\n",
      "0.0\n",
      "26.319999999999993\n",
      "84.21000000000001\n",
      "2.6299999999999955\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.646625614725053 0.9924509310518369 8.740245580673218 0.0 6.716772198677063 0.3458646616541353 116.0941321849823\n",
      "Gain in accuracy:  3.383458646616539\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           21.05 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           71.05 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           39.47 |\n",
      "|       5 |            100 |           73.68 |\n",
      "|       6 |              0 |            0    |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "36.84\n",
      "71.05\n",
      "0.0\n",
      "39.47\n",
      "73.68\n",
      "0.0\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.18597779981792 0.9950174389636273 7.684594988822937 0.16666666666666666 6.149657726287842 0.35714285714285715 136.38463735580444\n",
      "Gain in accuracy:  1.127819548872182\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             40 |           36.84 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           39.47 |\n",
      "|       5 |            100 |           76.32 |\n",
      "|       6 |             10 |            0    |\n",
      "Test accuracy is as follows - \n",
      "36.84\n",
      "34.209999999999994\n",
      "63.16\n",
      "0.0\n",
      "39.47\n",
      "76.32\n",
      "0.0\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.6417955085635185 0.9935865811544153 8.504867792129517 0.16666666666666666 7.295770645141602 0.3082706766917293 147.78227305412292\n",
      "Gain in accuracy:  -4.887218045112785\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           36.84 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           94.74 |\n",
      "|       6 |             20 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "36.84\n",
      "0.0\n",
      "28.950000000000003\n",
      "94.74\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 23, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.414485760964453 0.9960918417195896 8.004349827766418 0.26666666666666666 6.3856202363967896 0.35714285714285715 194.48123598098755\n",
      "Gain in accuracy:  4.887218045112785\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           26.32 |\n",
      "|       1 |            100 |           31.58 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             50 |           21.05 |\n",
      "Test accuracy is as follows - \n",
      "26.319999999999993\n",
      "31.58\n",
      "63.16\n",
      "0.0\n",
      "26.319999999999993\n",
      "81.58\n",
      "21.049999999999997\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 5, 6, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 25, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.976995322853327 0.9941944847605225 6.204482674598694 0.3 5.523527145385742 0.424812030075188 204.4478144645691\n",
      "Gain in accuracy:  6.766917293233085\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           31.58 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             60 |           47.37 |\n",
      "Test accuracy is as follows - \n",
      "31.58\n",
      "42.11\n",
      "63.16\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "47.37\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 27, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.60267810896039 0.9923334930522281 8.060025930404663 0.23333333333333334 6.269848942756653 0.37969924812030076 207.8608787059784\n",
      "Gain in accuracy:  -4.511278195488728\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           18.42 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             40 |           34.21 |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "39.47\n",
      "60.53\n",
      "0.0\n",
      "31.58\n",
      "81.58\n",
      "34.209999999999994\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 5, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.6858910927549005 0.9943046986236355 8.254692316055298 0.26666666666666666 6.505696415901184 0.3609022556390977 192.72645616531372\n",
      "Gain in accuracy:  -1.8796992481203034\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           26.32 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           47.37 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             60 |           26.32 |\n",
      "Test accuracy is as follows - \n",
      "26.319999999999993\n",
      "36.84\n",
      "47.37\n",
      "0.0\n",
      "31.58\n",
      "84.21000000000001\n",
      "26.319999999999993\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {25, 29, 27, 21}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.297608300112188 0.9915373765867419 8.099313259124756 0.23333333333333334 6.259846329689026 0.36466165413533835 164.8299207687378\n",
      "Gain in accuracy:  0.3759398496240678\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           13.16 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             50 |           28.95 |\n",
      "Test accuracy is as follows - \n",
      "13.159999999999997\n",
      "42.11\n",
      "55.26\n",
      "0.0\n",
      "23.680000000000007\n",
      "92.11\n",
      "28.950000000000003\n",
      "Total gain in accuracy:  2.631578947368425\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"SIM\",'gcmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36f379",
   "metadata": {
    "id": "07323a40"
   },
   "source": [
    "# LOGDETMI\n",
    "\n",
    "The SMI instantiation of LogDetMI can be defined as:\n",
    "\\begin{align}\n",
    "I_f(A;Q)=\\log\\det(S_{A}) -\\log\\det(S_{A} - \\eta^2 S_{A,Q}S_{Q}^{-1}S_{A,Q}^T)\n",
    "\\end{align}\n",
    "$S_{A, B}$ denotes the cross-similarity matrix between the items in sets $A$ and $B$. The similarity matrix in constructed in such a way that the cross-similarity between $A$ and $Q$ is multiplied by $\\eta$ to control the trade-off between query-relevance and diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ffcae14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02ad455b",
    "outputId": "32f1d0bb-f3dc-48c0-e273-9efc159d101a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/logdetmi/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./isic_2018_ResNet18_0.0003_7\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.733948176726699 0.9923741738688358 8.892418384552002 0.1 6.763710856437683 0.30451127819548873 117.45750904083252\n",
      "Gain in accuracy:  -3.383458646616539\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |            2.63 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             20 |            0    |\n",
      "Test accuracy is as follows - \n",
      "2.6299999999999955\n",
      "34.209999999999994\n",
      "55.26\n",
      "0.0\n",
      "31.58\n",
      "89.47\n",
      "0.0\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 23, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.695372964255512 0.9924509310518369 9.379138708114624 0.0 7.587606906890869 0.3157894736842105 158.8048758506775\n",
      "Gain in accuracy:  1.1278195488721785\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           18.42 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           57.89 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            0    |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "36.84\n",
      "57.89\n",
      "0.0\n",
      "23.680000000000007\n",
      "84.21000000000001\n",
      "0.0\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 23, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.034541294910014 0.9960139511709019 9.223466396331787 0.1 6.965001583099365 0.3157894736842105 148.59007668495178\n",
      "Gain in accuracy:  0.0\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           21.05 |\n",
      "|       1 |            100 |           28.95 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             30 |            0    |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "28.950000000000003\n",
      "63.16\n",
      "0.0\n",
      "26.319999999999993\n",
      "81.58\n",
      "0.0\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.773204422555864 0.9930932412432166 8.071191310882568 0.2 6.525548934936523 0.32706766917293234 156.25350403785706\n",
      "Gain in accuracy:  1.1278195488721856\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           18.42 |\n",
      "|       1 |            100 |           44.74 |\n",
      "|       2 |            100 |           47.37 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           21.05 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             40 |           15.79 |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "44.74\n",
      "47.37\n",
      "0.0\n",
      "21.049999999999997\n",
      "81.58\n",
      "15.790000000000006\n",
      "\n",
      " val_class_err_idxs -  [{0, 1, 2, 3, 4, 5, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.523486403748393 0.9965803615046409 7.404377460479736 0.2 7.126703381538391 0.3308270676691729 172.1861927509308\n",
      "Gain in accuracy:  0.3759398496240536\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           31.58 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           39.47 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           13.16 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             30 |           15.79 |\n",
      "Test accuracy is as follows - \n",
      "31.58\n",
      "39.47\n",
      "39.47\n",
      "0.0\n",
      "13.159999999999997\n",
      "92.11\n",
      "15.790000000000006\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 5, 7, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.99254908086732 0.9985486211901307 7.592033386230469 0.3 6.1652021408081055 0.3684210526315789 155.86717081069946\n",
      "Gain in accuracy:  3.7593984962405997\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             50 |           28.95 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           50    |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             40 |           15.79 |\n",
      "Test accuracy is as follows - \n",
      "28.950000000000003\n",
      "39.47\n",
      "50.0\n",
      "0.0\n",
      "31.58\n",
      "92.11\n",
      "15.790000000000006\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 5, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.997014990076423 0.996166746526114 7.1560773849487305 0.16666666666666666 6.951203465461731 0.33458646616541354 161.41562294960022\n",
      "Gain in accuracy:  -3.383458646616539\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           28.95 |\n",
      "|       1 |            100 |           23.68 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           18.42 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             20 |           18.42 |\n",
      "Test accuracy is as follows - \n",
      "28.950000000000003\n",
      "23.680000000000007\n",
      "55.26\n",
      "0.0\n",
      "18.42\n",
      "89.47\n",
      "18.42\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 6, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {20, 21, 22, 24, 25, 26, 27, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.573382667265832 0.9943046986236355 7.7256019115448 0.16666666666666666 6.753327131271362 0.3233082706766917 164.88956260681152\n",
      "Gain in accuracy:  -1.127819548872182\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           21.05 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           39.47 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             20 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "39.47\n",
      "39.47\n",
      "0.0\n",
      "31.58\n",
      "92.11\n",
      "2.6299999999999955\n",
      "\n",
      " val_class_err_idxs -  [{1, 2, 3, 4, 5, 8, 9}, set(), set(), {10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, set(), set(), {21, 22, 24, 25, 26, 27, 28, 29}]\n",
      "Class with most misclassified examples is -  3\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.661079477518797 0.9943582510578279 7.971049070358276 0.13333333333333333 6.904584288597107 0.3157894736842105 172.2636833190918\n",
      "Gain in accuracy:  -0.7518796992481178\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           28.95 |\n",
      "|       1 |            100 |           28.95 |\n",
      "|       2 |            100 |           65.79 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           13.16 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             10 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "28.950000000000003\n",
      "28.950000000000003\n",
      "65.78999999999999\n",
      "0.0\n",
      "13.159999999999997\n",
      "81.58\n",
      "2.6299999999999955\n",
      "Total gain in accuracy:  -2.2556390977443606\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"SIM\",'logdetmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe59bb",
   "metadata": {
    "id": "b1ec7d2d"
   },
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c7ced3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9389578a",
    "outputId": "58a78ce2-d769-47d2-9e5c-f3a8dfe8188e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/random/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./isic_2018_ResNet18_0.0003_7\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.137067838571966 0.9974580579562786 7.737208366394043 0.13333333333333333 6.68784773349762 0.3609022556390977 147.56454992294312\n",
      "Gain in accuracy:  2.255639097744357\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           28.95 |\n",
      "|       1 |            100 |           47.37 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             10 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "28.950000000000003\n",
      "47.37\n",
      "55.26\n",
      "0.0\n",
      "26.319999999999993\n",
      "92.11\n",
      "2.6299999999999955\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.777818905189633 0.9949672873678913 7.652583599090576 0.13333333333333333 6.2152259349823 0.3458646616541353 138.6202313899994\n",
      "Gain in accuracy:  -1.5037593984962356\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             40 |           34.21 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           50    |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |              0 |            7.89 |\n",
      "Test accuracy is as follows - \n",
      "34.209999999999994\n",
      "34.209999999999994\n",
      "50.0\n",
      "0.0\n",
      "28.950000000000003\n",
      "86.84\n",
      "7.890000000000001\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.680666726082563 0.992526158445441 9.287626504898071 0.06666666666666667 6.957810640335083 0.31203007518796994 142.4953453540802\n",
      "Gain in accuracy:  -3.383458646616539\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           15.79 |\n",
      "|       1 |            100 |           26.32 |\n",
      "|       2 |            100 |           57.89 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           34.21 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             10 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "26.319999999999993\n",
      "57.89\n",
      "0.0\n",
      "34.209999999999994\n",
      "81.58\n",
      "2.6299999999999955\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.301036580000073 0.9906265416872225 7.410532593727112 0.16666666666666666 6.474836230278015 0.32706766917293234 143.43537831306458\n",
      "Gain in accuracy:  1.5037593984962427\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           21.05 |\n",
      "|       1 |            100 |           31.58 |\n",
      "|       2 |            100 |           52.63 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           18.42 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             20 |           15.79 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "31.58\n",
      "52.63\n",
      "0.0\n",
      "18.42\n",
      "89.47\n",
      "15.790000000000006\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 9.286366321146488 0.9907181240840254 7.327955484390259 0.2 5.94955849647522 0.3684210526315789 131.01890063285828\n",
      "Gain in accuracy:  4.135338345864653\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           21.05 |\n",
      "|       1 |            100 |           47.37 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           18.42 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             40 |           18.42 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "47.37\n",
      "63.16\n",
      "0.0\n",
      "18.42\n",
      "89.47\n",
      "18.42\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.269871431402862 0.9966134494436382 8.177125215530396 0.13333333333333333 6.730586528778076 0.3458646616541353 166.26523780822754\n",
      "Gain in accuracy:  -2.255639097744357\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           13.16 |\n",
      "|       1 |            100 |           31.58 |\n",
      "|       2 |            100 |           65.79 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           36.84 |\n",
      "|       5 |            100 |           78.95 |\n",
      "|       6 |             20 |           15.79 |\n",
      "Test accuracy is as follows - \n",
      "13.159999999999997\n",
      "31.58\n",
      "65.78999999999999\n",
      "0.0\n",
      "36.84\n",
      "78.95\n",
      "15.790000000000006\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.260987034067512 0.9923334930522281 7.682291030883789 0.13333333333333333 6.20632266998291 0.33458646616541354 130.91570281982422\n",
      "Gain in accuracy:  -1.127819548872182\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           21.05 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           36.84 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           21.05 |\n",
      "|       5 |            100 |           94.74 |\n",
      "|       6 |             20 |           18.42 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "42.11\n",
      "36.84\n",
      "0.0\n",
      "21.049999999999997\n",
      "94.74\n",
      "18.42\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.857858621515334 0.9971523493118177 7.339083671569824 0.1 6.158596515655518 0.37969924812030076 149.61309480667114\n",
      "Gain in accuracy:  4.511278195488721\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           28.95 |\n",
      "|       1 |            100 |           50    |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           34.21 |\n",
      "|       5 |            100 |           76.32 |\n",
      "|       6 |              0 |           13.16 |\n",
      "Test accuracy is as follows - \n",
      "28.950000000000003\n",
      "50.0\n",
      "63.16\n",
      "0.0\n",
      "34.209999999999994\n",
      "76.32\n",
      "13.159999999999997\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.443873405456543 0.996238834038552 6.951060056686401 0.13333333333333333 5.670688152313232 0.37593984962406013 148.8592987060547\n",
      "Gain in accuracy:  -0.3759398496240607\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           21.05 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           52.63 |\n",
      "|       3 |              0 |            2.63 |\n",
      "|       4 |            100 |           34.21 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             30 |           18.42 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "42.11\n",
      "52.63\n",
      "2.6299999999999955\n",
      "34.209999999999994\n",
      "92.11\n",
      "18.42\n",
      "Total gain in accuracy:  3.7593984962405997\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"random\",'random')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eef186",
   "metadata": {
    "id": "d70fddb5"
   },
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ab4da5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6164c9b4",
    "outputId": "84d3b099-54d2-47d8-e4e7-1227778c17b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/us/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./isic_2018_ResNet18_0.0003_7\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.019705403596163 0.9928825622775801 7.73604941368103 0.13333333333333333 6.72761082649231 0.3383458646616541 148.89527320861816\n",
      "Gain in accuracy:  0.0\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           28.95 |\n",
      "|       1 |            100 |           52.63 |\n",
      "|       2 |            100 |           36.84 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           21.05 |\n",
      "|       5 |            100 |           92.11 |\n",
      "|       6 |             10 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "28.950000000000003\n",
      "52.63\n",
      "36.84\n",
      "0.0\n",
      "21.049999999999997\n",
      "92.11\n",
      "5.260000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.7441131118685 0.9919476597886261 7.333167791366577 0.16666666666666666 5.908312678337097 0.34210526315789475 134.10759615898132\n",
      "Gain in accuracy:  0.3759398496240607\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           10.53 |\n",
      "|       1 |            100 |           47.37 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             30 |           10.53 |\n",
      "Test accuracy is as follows - \n",
      "10.530000000000001\n",
      "47.37\n",
      "60.53\n",
      "0.0\n",
      "28.950000000000003\n",
      "81.58\n",
      "10.530000000000001\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.370904536917806 0.9955156950672646 7.950268030166626 0.13333333333333333 6.61234986782074 0.3157894736842105 165.4284863471985\n",
      "Gain in accuracy:  -2.6315789473684212\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |             10 |            2.63 |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           76.32 |\n",
      "|       6 |             10 |            0    |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "42.11\n",
      "60.53\n",
      "2.6299999999999955\n",
      "23.680000000000007\n",
      "76.32\n",
      "0.0\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.665634771808982 0.9985199802664035 6.843242406845093 0.13333333333333333 6.021656394004822 0.3609022556390977 142.29068064689636\n",
      "Gain in accuracy:  4.511278195488718\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           26.32 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |             10 |            2.63 |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           81.58 |\n",
      "|       6 |             10 |           13.16 |\n",
      "Test accuracy is as follows - \n",
      "26.319999999999993\n",
      "36.84\n",
      "63.16\n",
      "2.6299999999999955\n",
      "28.950000000000003\n",
      "81.58\n",
      "13.159999999999997\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.394265625625849 0.9936492427943332 7.656509637832642 0.23333333333333334 6.594176769256592 0.3383458646616541 148.14423632621765\n",
      "Gain in accuracy:  -2.255639097744357\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           21.05 |\n",
      "|       1 |            100 |           47.37 |\n",
      "|       2 |            100 |           47.37 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           10.53 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             60 |           23.68 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "47.37\n",
      "47.37\n",
      "0.0\n",
      "10.530000000000001\n",
      "86.84\n",
      "23.680000000000007\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 8.887642549350858 0.9908079342041606 8.641566038131714 0.16666666666666666 6.562490105628967 0.33458646616541354 144.23474836349487\n",
      "Gain in accuracy:  -0.3759398496240607\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           23.68 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           50    |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           94.74 |\n",
      "|       6 |             20 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "23.680000000000007\n",
      "36.84\n",
      "50.0\n",
      "0.0\n",
      "23.680000000000007\n",
      "94.74\n",
      "5.260000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.749256460927427 0.9956875898418783 8.208887100219727 0.13333333333333333 6.686522603034973 0.31954887218045114 147.657297372818\n",
      "Gain in accuracy:  -1.5037593984962356\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           18.42 |\n",
      "|       1 |            100 |           44.74 |\n",
      "|       2 |            100 |           50    |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           26.32 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             20 |            0    |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "44.74\n",
      "50.0\n",
      "0.0\n",
      "26.319999999999993\n",
      "84.21000000000001\n",
      "0.0\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.397977081127465 0.9900332225913622 9.803157329559326 0.1 7.017663478851318 0.3233082706766917 151.67489862442017\n",
      "Gain in accuracy:  0.3759398496240536\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           15.79 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           15.79 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             20 |            7.89 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "36.84\n",
      "63.16\n",
      "0.0\n",
      "15.790000000000006\n",
      "86.84\n",
      "7.890000000000001\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 3.627666406799108 0.996238834038552 6.997895956039429 0.23333333333333334 6.352975249290466 0.39097744360902253 193.46250867843628\n",
      "Gain in accuracy:  6.766917293233085\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           31.58 |\n",
      "|       1 |            100 |           42.11 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             50 |           26.32 |\n",
      "Test accuracy is as follows - \n",
      "31.58\n",
      "42.11\n",
      "60.53\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "26.319999999999993\n",
      "Total gain in accuracy:  5.2631578947368425\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"AL\",'us')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f18743",
   "metadata": {
    "id": "ebc215ed"
   },
   "source": [
    "# BADGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c27dd0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61e524cd",
    "outputId": "37e4d019-520a-4891-94ab-7a01324325b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC_2018 Custom dataset stats: Train size:  1947 Val size:  30 Lake size:  7772\n",
      "Indices of randomly selected classes for imbalance:  [0, 1, 2, 3, 4, 5, 6]\n",
      "Saving results to:  ./results/isic_2018/longtail/badge/20/exp_5_1\n",
      "Initial training epoch\n",
      "Init model loaded from disk, skipping init training:  ./isic_2018_ResNet18_0.0003_7\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           68.42 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |              0 |            5.26 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "68.42\n",
      "0.0\n",
      "28.950000000000003\n",
      "84.21000000000001\n",
      "5.260000000000005\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1967  unlabeled set:  7752  val set:  30\n",
      "Epoch: 2 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.660158200189471 0.9913573970513472 7.304812669754028 0.26666666666666666 6.081617116928101 0.34210526315789475 129.08469438552856\n",
      "Gain in accuracy:  0.3759398496240607\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             50 |           21.05 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           57.89 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             30 |            7.89 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "36.84\n",
      "57.89\n",
      "0.0\n",
      "28.950000000000003\n",
      "86.84\n",
      "7.890000000000001\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  1987  unlabeled set:  7732  val set:  30\n",
      "Epoch: 3 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 5.530823656357825 0.9944640161046804 8.862638711929321 0.0 7.325334072113037 0.29699248120300753 152.1208415031433\n",
      "Gain in accuracy:  -4.511278195488721\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |            7.89 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           15.79 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |              0 |            0    |\n",
      "Test accuracy is as follows - \n",
      "7.890000000000001\n",
      "34.209999999999994\n",
      "63.16\n",
      "0.0\n",
      "15.790000000000006\n",
      "86.84\n",
      "0.0\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2007  unlabeled set:  7712  val set:  30\n",
      "Epoch: 4 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.850304625928402 0.9900348779272546 8.493921995162964 0.1 6.520149230957031 0.33458646616541354 144.83092713356018\n",
      "Gain in accuracy:  3.7593984962405997\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           23.68 |\n",
      "|       1 |            100 |           26.32 |\n",
      "|       2 |            100 |           63.16 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           18.42 |\n",
      "|       5 |            100 |           94.74 |\n",
      "|       6 |             10 |            7.89 |\n",
      "Test accuracy is as follows - \n",
      "23.680000000000007\n",
      "26.319999999999993\n",
      "63.16\n",
      "0.0\n",
      "18.42\n",
      "94.74\n",
      "7.890000000000001\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2027  unlabeled set:  7692  val set:  30\n",
      "Epoch: 5 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.852175244130194 0.9950666008880118 9.460353374481201 0.03333333333333333 7.697349548339844 0.34210526315789475 155.56268572807312\n",
      "Gain in accuracy:  0.7518796992481214\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |              0 |           13.16 |\n",
      "|       1 |            100 |           52.63 |\n",
      "|       2 |            100 |           71.05 |\n",
      "|       3 |             10 |            0    |\n",
      "|       4 |            100 |           15.79 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |              0 |            0    |\n",
      "Test accuracy is as follows - \n",
      "13.159999999999997\n",
      "52.63\n",
      "71.05\n",
      "0.0\n",
      "15.790000000000006\n",
      "86.84\n",
      "0.0\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2047  unlabeled set:  7672  val set:  30\n",
      "Epoch: 6 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 4.107834256021306 0.9970688812896922 8.719008207321167 0.16666666666666666 6.690980076789856 0.3308270676691729 157.66485929489136\n",
      "Gain in accuracy:  -1.127819548872182\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           13.16 |\n",
      "|       1 |            100 |           36.84 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             40 |           10.53 |\n",
      "Test accuracy is as follows - \n",
      "13.159999999999997\n",
      "36.84\n",
      "60.53\n",
      "0.0\n",
      "23.680000000000007\n",
      "86.84\n",
      "10.530000000000001\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2067  unlabeled set:  7652  val set:  30\n",
      "Epoch: 7 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.419827496167272 0.9912917271407837 8.725090742111206 0.13333333333333333 7.126822471618652 0.38721804511278196 152.54101371765137\n",
      "Gain in accuracy:  5.639097744360903\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           21.05 |\n",
      "|       1 |            100 |           65.79 |\n",
      "|       2 |            100 |           65.79 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           28.95 |\n",
      "|       5 |            100 |           86.84 |\n",
      "|       6 |             20 |            2.63 |\n",
      "Test accuracy is as follows - \n",
      "21.049999999999997\n",
      "65.78999999999999\n",
      "65.78999999999999\n",
      "0.0\n",
      "28.950000000000003\n",
      "86.84\n",
      "2.6299999999999955\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2087  unlabeled set:  7632  val set:  30\n",
      "Epoch: 8 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.464219722896814 0.9976042165788213 7.610308647155762 0.16666666666666666 6.272227764129639 0.32706766917293234 132.05620980262756\n",
      "Gain in accuracy:  -6.015037593984957\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             10 |           15.79 |\n",
      "|       1 |            100 |           26.32 |\n",
      "|       2 |            100 |           60.53 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           23.68 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             40 |           18.42 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "26.319999999999993\n",
      "60.53\n",
      "0.0\n",
      "23.680000000000007\n",
      "84.21000000000001\n",
      "18.42\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2107  unlabeled set:  7612  val set:  30\n",
      "Epoch: 9 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 6.728880571201444 0.9914570479354533 8.202093362808228 0.13333333333333333 7.162019371986389 0.31954887218045114 157.90097069740295\n",
      "Gain in accuracy:  -0.7518796992481214\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             20 |           18.42 |\n",
      "|       1 |            100 |           39.47 |\n",
      "|       2 |            100 |           52.63 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           15.79 |\n",
      "|       5 |            100 |           84.21 |\n",
      "|       6 |             20 |           13.16 |\n",
      "Test accuracy is as follows - \n",
      "18.42\n",
      "39.47\n",
      "52.63\n",
      "0.0\n",
      "15.790000000000006\n",
      "84.21000000000001\n",
      "13.159999999999997\n",
      "#### Selection Complete, Now re-training with augmented subset ####\n",
      "After augmentation, size of train_set:  2127  unlabeled set:  7592  val set:  30\n",
      "Epoch: 10 FullTrn,TrainAcc,ValLoss,ValAcc,TstLoss,TstAcc,Time: 7.904109390452504 0.9905970850963799 8.056060314178467 0.2 6.732515215873718 0.3533834586466165 134.6199038028717\n",
      "Gain in accuracy:  3.383458646616539\n",
      "**** Final Metrics after Targeted Learning ****\n",
      "|   Class |   Val Accuracy |   Test Accuracy |\n",
      "|---------+----------------+-----------------|\n",
      "|       0 |             30 |           15.79 |\n",
      "|       1 |            100 |           34.21 |\n",
      "|       2 |            100 |           55.26 |\n",
      "|       3 |              0 |            0    |\n",
      "|       4 |            100 |           31.58 |\n",
      "|       5 |            100 |           89.47 |\n",
      "|       6 |             30 |           21.05 |\n",
      "Test accuracy is as follows - \n",
      "15.790000000000006\n",
      "34.209999999999994\n",
      "55.26\n",
      "0.0\n",
      "31.58\n",
      "89.47\n",
      "21.049999999999997\n",
      "Total gain in accuracy:  1.5037593984962427\n"
     ]
    }
   ],
   "source": [
    "run_targeted_selection(data_name, \n",
    "               datadir, \n",
    "               feature, \n",
    "               model_name, \n",
    "               budget, \n",
    "               split_cfg, \n",
    "               learning_rate, \n",
    "               run, \n",
    "               device, \n",
    "               computeClassErrorLog,\n",
    "               \"AL\",'badge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99943940",
   "metadata": {
    "id": "4ecf8b9c"
   },
   "source": [
    "# References\n",
    "[1] Rishabh Iyer, Ninad Khargoankar, Jeff Bilmes, and Himanshu Asnani. Submodular combinatorialinformation measures with applications in machine learning.arXiv preprint arXiv:2006.15412,2020\n",
    "\n",
    "\n",
    "[2] Kaushal V, Kothawade S, Ramakrishnan G, Bilmes J, Iyer R. PRISM: A Unified Framework of Parameterized Submodular Information Measures for Targeted Data Subset Selection and Summarization. arXiv preprint arXiv:2103.00128. 2021 Feb 27.\n",
    "\n",
    "\n",
    "[3] Anupam Gupta and Roie Levin. The online submodular cover problem. InACM-SIAM Symposiumon Discrete Algorithms, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c652f0b9",
   "metadata": {
    "id": "e93a22fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete all strategies is - 187.04854519049792 mins\n"
     ]
    }
   ],
   "source": [
    "end_time = time.monotonic()\n",
    "print('Time to complete all strategies is -', (end_time - start_time)/60, 'mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d88900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "trust_rare_classes_demo_dermamnist_targeted.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
